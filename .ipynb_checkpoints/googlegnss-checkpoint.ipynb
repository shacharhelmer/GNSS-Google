{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Smartphone Decimeter Challenge\n",
    "##### Improve high precision GNSS positioning and navigation accuracy on smartphones\n",
    "\n",
    "## Intro\n",
    "We are Nitzan Karni (208939215) and Shachar Helmer (318439833) both of us are toward the end of our computer science degree, and eager to specialize in data science. Both of us have a day to day interaction with data engineering, data analysis and even machine learning at times. In the data science world the possiblities are endless. While choosing a topic for this project countless of ambitious ideas were thrown into the air was - From old (19th century) picture colorization using Generative Advarsarial Networks to Radio Signal anomaly detection to natural language coding using GPT3 to translate english to code. Eventually with huge number of incomplete idea we got together and decided to decide once and for all. We browsed the web and kaggle for hours and then we encounter a fresh new challenge that had been uploaded at the same day: \"Google Smartphone Decimeter Challenge\", it was a sign from heavens! \n",
    "Due to the fact that Nitzan is working on his \"Autonomous cars and Swarm intelligence algorithms\" seminar in parallel and our common interest in Autonomous vehicles technologies - trying to solve the navigation positioning problem by using Data Science is the right fit for us.\n",
    "\n",
    "## About The Problem\n",
    "\n",
    "We believe there is no better explenation to the problem than the original challenge description: https://www.kaggle.com/c/google-smartphone-decimeter-challenge/overview\n",
    "<br><br>\n",
    "Have you ever hit a surprise pothole or other road obstruction? Do you wish your navigation app could provide more precise location or lane-level accuracy? These and other novel features are powered by smartphone positioning services. Machine learning and precision GNSS algorithms are expected to improve this accuracy and provide billions of Android phone users with a more fine-tuned positioning experience.\n",
    "<br><br>\n",
    "Global Navigation Satellite System (GNSS) provides raw signals, which the GPS chipset uses to compute a position. Current mobile phones only offer 3-5 meters of positioning accuracy. While useful in many cases, it can create a “jumpy” experience. For many use cases the results are not fine nor stable enough to be reliable.\n",
    "<br><br>\n",
    "This competition, hosted by the Android GPS team, is being presented at the ION GNSS+ 2021 Conference. They seek to advance research in smartphone GNSS positioning accuracy and help people better navigate the world around them.\n",
    "<br><br>\n",
    "In this competition, you'll use data collected from the host team’s own Android phones to compute location down to decimeter or even centimeter resolution, if possible. You'll have access to precise ground truth, raw GPS measurements, and assistance data from nearby GPS stations, in order to train and test your submissions.\n",
    "<br><br>\n",
    "If successful, you'll help produce more accurate positions, bridging the connection between the geospatial information of finer human behavior and mobile internet with much finer granularity. Mobile users could gain better lane-level coordinates, enhanced experience in location-based gaming, and greater specificity in the location of road safety issues. You may even notice it's easier to get you where you need to go.\n",
    "<br>\n",
    "\n",
    "##### Our no. 1 objective\n",
    "Predict phone positioning at each sample to finest granuality possible from given measurements of GNSS system and other phone instruments such as accelometer & gyro. \n",
    "\n",
    "## The Data\n",
    "Our whole dataset in the competition is comprised of several data sources such as GNSS and phone insruments measurments.<br>\n",
    "All the data can be achieved using simple android smartphone.<br>\n",
    "The dataset we will use in this contest is consists of collections that have been collected separatly.<br>\n",
    "Each collection had been measured using the following method:<br>\n",
    "A car with at least one android device starts taking it's GNSS and phone insruments measurments and the Ground truth measurement reciever which will be explained in further details later on, drive around the city for a while and then stop the collection. <br>\n",
    "Most of the samples are from the silicon valley area around Google HQ.<br>\n",
    "The collections that had been collected over the course of approximatly one year.<br><br>\n",
    "An Example of a phone and reciever setup inside the car:\n",
    "![alt text](fig3_fig4.jpg \"An Example of a phone and reciever setup inside the car\")\n",
    "One trace consists of the following data for each android device that had been used in the process:<br>\n",
    "* `ground_truth.csv` - a csv file containing the correct specific positions in The WGS84 latitude, longitude (in decimal degrees) estimated by the reference GNSS receiver (NovAtel SPAN).<br>\n",
    "    the receiver is a preciese GNSS reciever, specific for the task piece of hardware that is installed in the car and can provide the exact locations of the car at each timestamp<br>\n",
    "    In addition to the GNSS receiver an IMU (Inertial Measurement Units) device is installed to accurratly measure the speed and courseDegree of the trace.<br>\n",
    "    The dataset consists the following features for each sample:\n",
    "    > `millisSinceGpsEpoch ` - An integer number of milliseconds since the GPS epoch (1980/1/6 midnight UTC). from our observations it seems that the samples are sampled at a 1s intervals.<br>\n",
    "    > `latDeg, lngDeg` - The latitude and longitude degrees from the center of the he WGS84 axis system. These features are out target features and we would like to predict these values.<br>\n",
    "    > ![alt text](280px-WGS_84_reference_frame_(vector_graphic).svg.png \"WGS_84 axis\")\n",
    "    > `heightAboveWgs84EllipsoidM ` - The WGS84 ellipsoid is a representation of earth (earth is actually round but more elliptical), the following feature represents the hight above the surface of the ellipsoid<br>\n",
    "    > `hDop, vDop` - Horizontal / Vertical dilution of precision. describes how errors in the measurements affect the final horizontal /vertical position estimation.  The idea of Geometric DOP is to state how errors in the measurement will affect the final state estimation.Conceptually you can geometrically imagine errors on a measurement resulting in the delta term changing<br>\n",
    "    > `speedMps` - The speed over ground in meters per second.<br>\n",
    "    > `courseDegree` - The course angle clockwise with respect to the truth north over ground (in degrees).\n",
    "    \n",
    "* `[phone_name]_GnssLog.txt` The GnssLogger App calls the google GNSS API and creates a text file containing at each file the full scale dataset for each sample<br>\n",
    "    - `Raw` - The raw GNSS measurements of one GNSS signal (each satellite may have 1-2 signals for L5-enabled smartphones), collected from the Android API GnssMeasurement.\n",
    "    - `Status` - The status of a GNSS signal, as collected from the Android API GnssStatus.\n",
    "    - `UncalAccel` -  Readings from the uncalibrated accelerometer\n",
    "    - `UncalGyro` - Readings from the uncalibrated gyroscope\n",
    "    - `UncalMag` - Readings from the uncalibrated magnetometer\n",
    "    - `OrientationDeg` - Each row represents an estimated device orientation\n",
    "    \n",
    "* `[phone_name]_derived.csv` - derived dataset is  GNSS intermediate values derived from raw GNSS measurements, provided for convenience. With these derived values, a corrected pseudorange (i.e. a closer approximation to the geometric range from the phone to the satellite) can be computed as: correctedPrM = rawPrM + satClkBiasM - isrbM - ionoDelayM - tropoDelayM. The baseline locations are computed using correctedPrM and the satellite positions, using a standard Weighted Least Squares (WLS) solver, with the phone's position (x, y, z), clock bias (t), and isrbM for each unique signal type as states for each epoch.<br>\n",
    "    > A sample from android GNSS comprised of communication with several satelites.<br>\n",
    "    > For each satelite we are measuring several metrics here is an example of several important ones:<br>\n",
    "    > `collectionName` - The ID of the collection<br>\n",
    "    > `phoneName` - The name of phone<br>\n",
    "    > `svid` - The satelite id.<br>\n",
    "    > `millisSinceGpsEpoch`- the same as in `ground_truth.csv`<br>\n",
    "    > `rawPrM` - Raw pseudorange in meters. It is the product between the speed of light and the time difference from the signal transmission time (receivedSvTimeInGpsNanos) to the signal arrival time (Raw::TimeNanos - Raw::FullBiasNanos - Raw::BiasNanos).<br>\n",
    "    This is an important feature because actually for every measurement we can roughly calculate from the distance to the satelites and the satelites positions and velocities the exact point on earth surface using triangulation methods and intersect the data. we personally do not know much about the correct equations for this complex calculations but we can try later on using learning methods to generate a model based on these features.  \n",
    "    > `[x/y/z]SatPosM` - The satellite position (meters) in an ECEF coordinate frame at best estimate of “true signal transmission time” defined as ttx = receivedSvTimeInGpsNanos - satClkBiasNanos (defined below). They are computed with the satellite broadcast ephemeris, and have ~1-meter error with respect to the true satellite position.<br>\n",
    "    > `[x/y/z]SatVelMps` - The satellite velocity (meters per second) in an ECEF coordinate frame at the signal transmission time (receivedSvTimeInGpsNanos). They are computed with the satellite broadcast ephemeris, with this algorithm.<br>\n",
    "    > `constellationType` - GNSS constellation type. An integer number, whose mapping string value is provided in constellation_type_mapping.csv.<br>\n",
    "    > `signalType` - The GNSS signal type is a combination of the constellation name and the frequency band.<br>\n",
    "    > `receivedSvTimeInGpsNanos` - The signal transmission time received by the chipset.<br>\n",
    "\n",
    ".<br><br><br>`baseline_locations_[train/test].csv` - The following is the most similar to `ground_truth.csv` format. It is a tabular dataset which every table row represents a single measurement in one of our phones. That means that each row is refered to specific collection `collectionName`(for example Mountain View at 7/4/21) using specific phone `phoneName`(f.e. Pixel4) at specific timestamp`millisSinceGpsEpoch`. In addition the only features in the dataset are the features which exists in `ground_truth.csv`.<br>\n",
    "This dataset was generated using a standard Weighted Least Squares (WLS) approach run on the raw GNSS measurements. Similar WLS implementations can be found in RTKLib and the public version of Android GPS tools.\n",
    "<br><br>\n",
    "Each dataset has a train and test version except ground truth. <br>\n",
    "Using the test datasets we need to predict this value and submit our results.\n",
    "All datasets are present both for training data as well as for the test data\n",
    "\n",
    "For further reading on the Data please refer to: https://www.kaggle.com/c/google-smartphone-decimeter-challenge/data\n",
    "\n",
    "### Some Domain Knowledge\n",
    "Earth is surrounded by navigation satelite systems.<br>\n",
    "Overall there are 4 global navigation systems and 2 local, ones around India and most of south Asia and another japanese one that cover most of east Asia and Oceania (Pacific Ocean and Australia region).<br>\n",
    "Each sample also contains satelite atomic clock metrics and several parameters that can affect the delay and noise of the measurements such as clock drift, ionospheric layer delay, tropospheric layer delay (Layers of earth's sky that can cause measurement deviation, similar to the well known Atmosphere layer).<br>\n",
    "Essentially the phone will try and communicated with as many satelites it can reach from its position. The more the merrier.<br>In our final calculation the more data we can interpolate regarding the positioning of the phone the finer our result would get. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gast in c:\\users\\nitza\\anaconda3\\lib\\site-packages (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install gast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import gmplot\n",
    "from IPython.display import IFrame\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import seaborn as sns\n",
    "import simdkalman\n",
    "from tqdm.notebook import tqdm\n",
    "#import tensorflow_probability as tfp\n",
    "from functools import reduce\n",
    "import math\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will iterate through the folder structure to setup our derived & ground truth dataframes.<br>\n",
    "The datasets are ordered in file hierarchy and the following methods are going through the collections and generate one unified<br>\n",
    "dataset, it is needed for the ground_truth dataset (the target variable) and for the derived data (the data which we are going to train our model on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_files_to_df(path_list):\n",
    "    \"\"\"\n",
    "    Read a list of structured files in csv format, concatenating them into a single DataFrame\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path_list: list of paths to csv datasets\n",
    "    \"\"\"\n",
    "    return reduce(lambda df1, df2: pd.concat([df1, df2]), [pd.read_csv(s) for s in path_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def simplify_set_file_name(file_name):\n",
    "    \"\"\"\n",
    "    Convert the collection name to human readble format according to:\n",
    "    [train]/[drive_id]/[phone_name]/\n",
    "    \"\"\"\n",
    "    path_rest = file_name.split('google-smartphone-decimeter-challenge/')[1]\n",
    "    trn_grnd = path_rest.split('/')[0]\n",
    "    path_rest = path_rest.replace(f'{trn_grnd}/', '')\n",
    "    date = path_rest.split('/')[0]\n",
    "    path_rest = path_rest.replace(f'{date}/', '')\n",
    "    phone = path_rest.split('/')[0]\n",
    "    return f'{trn_grnd} | {date} | {phone}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnss_log_to_dataframes(path):\n",
    "    \"\"\"\n",
    "    Parse a gnss log file and read it into a dataframe\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: location of the gnss log to parse\n",
    "    \"\"\"\n",
    "    print('Loading ' + path, flush=True)\n",
    "    gnss_section_names = {'Raw','UncalAccel', 'UncalGyro', 'UncalMag', 'Fix', 'Status', 'OrientationDeg'}\n",
    "    with open(path) as f_open:\n",
    "        datalines = f_open.readlines()\n",
    "\n",
    "    datas = {k: [] for k in gnss_section_names}\n",
    "    gnss_map = {k: [] for k in gnss_section_names}\n",
    "    error_count = 0\n",
    "    for dataline in datalines:\n",
    "        try:\n",
    "            is_header = dataline.startswith('#')\n",
    "            dataline = dataline.strip('#').strip().split(',')\n",
    "            # skip over notes, version numbers, etc\n",
    "            if is_header and dataline[0] in gnss_section_names:\n",
    "                gnss_map[dataline[0]] = dataline[1:]\n",
    "            elif not is_header:\n",
    "                datas[dataline[0]].append(dataline[1:])\n",
    "        except KeyError as e:\n",
    "            error_count += 1            \n",
    "\n",
    "    results = dict()\n",
    "    for k, v in datas.items():\n",
    "        results[k] = pd.DataFrame(v, columns=gnss_map[k])\n",
    "    # pandas doesn't properly infer types from these lists by default\n",
    "    for k, df in results.items():\n",
    "        for col in df.columns:\n",
    "            if col == 'CodeType':\n",
    "                continue\n",
    "            results[k][col] = pd.to_numeric(results[k][col])\n",
    "\n",
    "    if error_count > 0:\n",
    "        print(f'{path} showed a {error_count} key error(s). Some log data rows for it might not be available.')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_log(path, log_sections=['UncalAccel', 'UncalGyro']):\n",
    "    \"\"\"\n",
    "    Takes in a gnss log file for a collection, parses it and outputs a single dataframe containing all properties specified (or the default ones)\n",
    "    from that gnss log, if they exist. They are merged based on the 'utcTimeMillis' field in an 'outer' fashion.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path: the path to the gnss log file\n",
    "    log_properties: the sub-sections to utilize from the log\n",
    "    \"\"\"\n",
    "    log = gnss_log_to_dataframes(path)\n",
    "    return reduce(lambda df1, df2: pd.merge_asof(df1, df2, on=['utcTimeMillis'], suffixes=['','']),\n",
    "                  [log[section].drop(['elapsedRealtimeNanos'], axis=1).sort_values('utcTimeMillis') for section in log_sections])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the list of datasets needed to be red into our project\n",
    "We will check how many train collections exists compared to the test ones.<br>\n",
    "In addition we will check the presence of the features in the datasets that we have read in order to avoid situations where a specific collection somehow missing a feature.<br>\n",
    "Each unique GPS sample has a varying amount of satelite samples describing it (rows in the derived data set), yet they all refer to the same time-location combination.</br>\n",
    "In the ground truth data set, samples are matched with rows in an \"on\" and \"one-to-one\" fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 train collections, 19 test collections\n",
      "\n",
      "Do all columns appear in all non-log data sets?\n",
      "Derived train data: True\n",
      "Ground truth train data: True\n",
      "Derived test data: True\n"
     ]
    }
   ],
   "source": [
    "base_data_dir = 'google-smartphone-decimeter-challenge'\n",
    "\n",
    "train_collections = [f'{base_data_dir}/train/{collection}' for collection in os.listdir(f'{base_data_dir}/train')]\n",
    "test_collections = [f'{base_data_dir}/test/{collection}' for collection in os.listdir(f'{base_data_dir}/test')]\n",
    "\n",
    "\n",
    "print(f'{len(train_collections)} train collections, {len(test_collections)} test collections\\n')\n",
    "\n",
    "derived_train_sets = [f'{c}/{s}/{s}_derived.csv' for c in train_collections for s in os.listdir(c)]\n",
    "ground_train_sets = [f'{c}/{s}/ground_truth.csv' for c in train_collections for s in os.listdir(c)]\n",
    "derived_test_sets = [f'{c}/{s}/{s}_derived.csv' for c in test_collections for s in os.listdir(c)]\n",
    "logs_test_sets = [f'{c}/{s}/{s}_GnssLog.txt' for c in test_collections for s in os.listdir(c)]\n",
    "logs_train_sets = [f'{c}/{s}/{s}_GnssLog.txt' for c in train_collections for s in os.listdir(c)]\n",
    "\n",
    "\n",
    "drvd_trn_clms = reduce(lambda s1, s2: s1.union(s2), [set(list(pd.read_csv(s, nrows=1).columns)) for s in derived_train_sets])\n",
    "grnd_trn_clms = reduce(lambda s1, s2: s1.union(s2), [set(list(pd.read_csv(s, nrows=1).columns)) for s in ground_train_sets])\n",
    "drvd_tst_clms = reduce(lambda s1, s2: s1.union(s2), [set(list(pd.read_csv(s, nrows=1).columns)) for s in derived_test_sets])\n",
    "print('Do all columns appear in all non-log data sets?')\n",
    "print(f'Derived train data: {drvd_trn_clms == set(list(pd.read_csv(derived_train_sets[0], nrows=1).columns))}')\n",
    "print(f'Ground truth train data: {grnd_trn_clms == set(list(pd.read_csv(ground_train_sets[0], nrows=1).columns))}')\n",
    "print(f'Derived test data: {drvd_tst_clms == set(list(pd.read_csv(derived_test_sets[0], nrows=1).columns))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading google-smartphone-decimeter-challenge/train/2020-05-14-US-MTV-1/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-05-14-US-MTV-1/Pixel4XLModded/Pixel4XLModded_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-05-14-US-MTV-2/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-05-14-US-MTV-2/Pixel4XLModded/Pixel4XLModded_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-05-21-US-MTV-1/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-05-21-US-MTV-2/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-05-21-US-MTV-2/Pixel4XL/Pixel4XL_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-05-29-US-MTV-1/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-05-29-US-MTV-1/Pixel4XL/Pixel4XL_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-05-29-US-MTV-1/Pixel4XLModded/Pixel4XLModded_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-05-29-US-MTV-2/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-05-29-US-MTV-2/Pixel4XL/Pixel4XL_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-06-04-US-MTV-1/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-06-04-US-MTV-1/Pixel4XL/Pixel4XL_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-06-04-US-MTV-1/Pixel4XLModded/Pixel4XLModded_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-06-05-US-MTV-1/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-06-05-US-MTV-1/Pixel4XL/Pixel4XL_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-06-05-US-MTV-1/Pixel4XLModded/Pixel4XLModded_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-06-05-US-MTV-2/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-06-05-US-MTV-2/Pixel4XL/Pixel4XL_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-06-11-US-MTV-1/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-06-11-US-MTV-1/Pixel4XL/Pixel4XL_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-07-08-US-MTV-1/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-07-08-US-MTV-1/Pixel4XL/Pixel4XL_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-07-08-US-MTV-1/Pixel4XLModded/Pixel4XLModded_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-07-17-US-MTV-1/Mi8/Mi8_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-07-17-US-MTV-2/Mi8/Mi8_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-08-03-US-MTV-1/Mi8/Mi8_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-08-03-US-MTV-1/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-08-06-US-MTV-2/Mi8/Mi8_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-08-06-US-MTV-2/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-08-06-US-MTV-2/Pixel4XL/Pixel4XL_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-09-04-US-SF-1/Mi8/Mi8_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-09-04-US-SF-1/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-09-04-US-SF-1/Pixel4XL/Pixel4XL_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-09-04-US-SF-2/Mi8/Mi8_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-09-04-US-SF-2/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2020-09-04-US-SF-2/Pixel4XL/Pixel4XL_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-01-04-US-RWC-1/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-01-04-US-RWC-1/Pixel4Modded/Pixel4Modded_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-01-04-US-RWC-1/Pixel4XL/Pixel4XL_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-01-04-US-RWC-1/Pixel5/Pixel5_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-01-04-US-RWC-2/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-01-04-US-RWC-2/Pixel4Modded/Pixel4Modded_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-01-04-US-RWC-2/Pixel4XL/Pixel4XL_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-01-04-US-RWC-2/Pixel5/Pixel5_GnssLog.txt\n",
      "google-smartphone-decimeter-challenge/train/2021-01-04-US-RWC-2/Pixel5/Pixel5_GnssLog.txt showed a 1 key error(s). Some log data rows for it might not be available.\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-01-05-US-SVL-1/Mi8/Mi8_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-01-05-US-SVL-1/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-01-05-US-SVL-1/Pixel4XL/Pixel4XL_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-01-05-US-SVL-1/Pixel5/Pixel5_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-01-05-US-SVL-2/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-01-05-US-SVL-2/Pixel4Modded/Pixel4Modded_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-01-05-US-SVL-2/Pixel4XL/Pixel4XL_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-03-10-US-SVL-1/Pixel4XL/Pixel4XL_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-03-10-US-SVL-1/SamsungS20Ultra/SamsungS20Ultra_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-04-15-US-MTV-1/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-04-15-US-MTV-1/Pixel4Modded/Pixel4Modded_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-04-15-US-MTV-1/Pixel5/Pixel5_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-04-15-US-MTV-1/SamsungS20Ultra/SamsungS20Ultra_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-04-22-US-SJC-1/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-04-22-US-SJC-1/SamsungS20Ultra/SamsungS20Ultra_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-04-26-US-SVL-1/Mi8/Mi8_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-04-26-US-SVL-1/Pixel5/Pixel5_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-04-28-US-MTV-1/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-04-28-US-MTV-1/Pixel5/Pixel5_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-04-28-US-MTV-1/SamsungS20Ultra/SamsungS20Ultra_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-04-28-US-SJC-1/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-04-28-US-SJC-1/SamsungS20Ultra/SamsungS20Ultra_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-04-29-US-MTV-1/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-04-29-US-MTV-1/Pixel5/Pixel5_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-04-29-US-MTV-1/SamsungS20Ultra/SamsungS20Ultra_GnssLog.txt\n",
      "google-smartphone-decimeter-challenge/train/2021-04-29-US-MTV-1/SamsungS20Ultra/SamsungS20Ultra_GnssLog.txt showed a 1 key error(s). Some log data rows for it might not be available.\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-04-29-US-SJC-2/Pixel4/Pixel4_GnssLog.txt\n",
      "Loading google-smartphone-decimeter-challenge/train/2021-04-29-US-SJC-2/SamsungS20Ultra/SamsungS20Ultra_GnssLog.txt\n",
      "Finished reading logs\n",
      "# of records in all GNSS train logs: 20523372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_dfs = [read_log(c) for c in logs_train_sets]\n",
    "print('Finished reading logs')\n",
    "logs = reduce(lambda df1, df2: pd.concat([df1, df2]), log_dfs)\n",
    "print(\"# of records in all GNSS train logs: {}\\n\".format(logs.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate one unified dataset for derived ground truth data for ease of access and better training process.<br>\n",
    "Generate one unified dataset for derived train data for ease of access and better training process.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples in ground truth train dataset: 3834542\n",
      "# of samples in derived train dataset: 131342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "derived = read_files_to_df(derived_train_sets)\n",
    "ground = read_files_to_df(ground_train_sets)\n",
    "print(\"# of samples in ground truth train dataset: {}\\n# of samples in derived train dataset: {}\\n\".format(derived.shape[0], ground.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collectionName</th>\n",
       "      <th>phoneName</th>\n",
       "      <th>millisSinceGpsEpoch</th>\n",
       "      <th>constellationType</th>\n",
       "      <th>svid</th>\n",
       "      <th>signalType</th>\n",
       "      <th>receivedSvTimeInGpsNanos</th>\n",
       "      <th>xSatPosM</th>\n",
       "      <th>ySatPosM</th>\n",
       "      <th>zSatPosM</th>\n",
       "      <th>xSatVelMps</th>\n",
       "      <th>ySatVelMps</th>\n",
       "      <th>zSatVelMps</th>\n",
       "      <th>satClkBiasM</th>\n",
       "      <th>satClkDriftMps</th>\n",
       "      <th>rawPrM</th>\n",
       "      <th>rawPrUncM</th>\n",
       "      <th>isrbM</th>\n",
       "      <th>ionoDelayM</th>\n",
       "      <th>tropoDelayM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-14-US-MTV-1</td>\n",
       "      <td>Pixel4</td>\n",
       "      <td>1273529464442</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>GLO_G1</td>\n",
       "      <td>1273529463363061857</td>\n",
       "      <td>-2.539901e+07</td>\n",
       "      <td>-692512.225</td>\n",
       "      <td>-2280429.834</td>\n",
       "      <td>-325.826</td>\n",
       "      <td>156.04</td>\n",
       "      <td>3559.757</td>\n",
       "      <td>-468.084</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2.379498e+07</td>\n",
       "      <td>11.992</td>\n",
       "      <td>1134.758</td>\n",
       "      <td>10.866</td>\n",
       "      <td>16.647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        collectionName phoneName  millisSinceGpsEpoch  constellationType  \\\n",
       "0  2020-05-14-US-MTV-1    Pixel4        1273529464442                  3   \n",
       "\n",
       "   svid signalType  receivedSvTimeInGpsNanos      xSatPosM    ySatPosM  \\\n",
       "0    24     GLO_G1       1273529463363061857 -2.539901e+07 -692512.225   \n",
       "\n",
       "      zSatPosM  xSatVelMps  ySatVelMps  zSatVelMps  satClkBiasM  \\\n",
       "0 -2280429.834    -325.826      156.04    3559.757     -468.084   \n",
       "\n",
       "   satClkDriftMps        rawPrM  rawPrUncM     isrbM  ionoDelayM  tropoDelayM  \n",
       "0           0.001  2.379498e+07     11.992  1134.758      10.866       16.647  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derived.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the baseline train and test data.<br>\n",
    "For further analysis create a target dataset which is simply ground thruth merged with the baseline predictions to align the samples using the ['collectionName', 'phoneName', 'millisSinceGpsEpoch'] index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsln_trn = pd.read_csv('google-smartphone-decimeter-challenge/baseline_locations_train.csv')\n",
    "bsln_tst = pd.read_csv('google-smartphone-decimeter-challenge/baseline_locations_test.csv')\n",
    "target = ground.merge(bsln_trn, how='inner', on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], suffixes=('_grnd', '_bsln'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utcTimeMillis</th>\n",
       "      <th>UncalAccelXMps2</th>\n",
       "      <th>UncalAccelYMps2</th>\n",
       "      <th>UncalAccelZMps2</th>\n",
       "      <th>UncalGyroXRadPerSec</th>\n",
       "      <th>UncalGyroYRadPerSec</th>\n",
       "      <th>UncalGyroZRadPerSec</th>\n",
       "      <th>BiasXMps2</th>\n",
       "      <th>BiasYMps2</th>\n",
       "      <th>BiasZMps2</th>\n",
       "      <th>DriftXRadPerSec</th>\n",
       "      <th>DriftYRadPerSec</th>\n",
       "      <th>DriftZRadPerSec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1589494244845</td>\n",
       "      <td>0.177860</td>\n",
       "      <td>10.159246</td>\n",
       "      <td>1.052928</td>\n",
       "      <td>-0.003550</td>\n",
       "      <td>0.023597</td>\n",
       "      <td>-0.082773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1589494244847</td>\n",
       "      <td>-0.002934</td>\n",
       "      <td>10.351667</td>\n",
       "      <td>0.934190</td>\n",
       "      <td>-0.003370</td>\n",
       "      <td>0.030998</td>\n",
       "      <td>-0.080377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1589494244850</td>\n",
       "      <td>-0.114138</td>\n",
       "      <td>10.099208</td>\n",
       "      <td>0.751948</td>\n",
       "      <td>-0.004533</td>\n",
       "      <td>0.028622</td>\n",
       "      <td>-0.074239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1589494244853</td>\n",
       "      <td>-0.089033</td>\n",
       "      <td>9.789539</td>\n",
       "      <td>0.821809</td>\n",
       "      <td>-0.008254</td>\n",
       "      <td>0.017697</td>\n",
       "      <td>-0.065580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1589494244856</td>\n",
       "      <td>-0.123533</td>\n",
       "      <td>9.586480</td>\n",
       "      <td>0.996857</td>\n",
       "      <td>-0.008272</td>\n",
       "      <td>0.010407</td>\n",
       "      <td>-0.058197</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237134</th>\n",
       "      <td>1619725101950</td>\n",
       "      <td>-1.668759</td>\n",
       "      <td>9.577106</td>\n",
       "      <td>-1.575385</td>\n",
       "      <td>0.007330</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.010996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002394</td>\n",
       "      <td>0.009269</td>\n",
       "      <td>0.007845</td>\n",
       "      <td>0.014271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237135</th>\n",
       "      <td>1619725101961</td>\n",
       "      <td>-1.479617</td>\n",
       "      <td>9.581895</td>\n",
       "      <td>-1.970428</td>\n",
       "      <td>0.018937</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>0.013439</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002394</td>\n",
       "      <td>0.009269</td>\n",
       "      <td>0.007845</td>\n",
       "      <td>0.014271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237136</th>\n",
       "      <td>1619725101970</td>\n",
       "      <td>-1.472434</td>\n",
       "      <td>9.433454</td>\n",
       "      <td>-1.565808</td>\n",
       "      <td>-0.004887</td>\n",
       "      <td>0.011606</td>\n",
       "      <td>0.015882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002394</td>\n",
       "      <td>0.009269</td>\n",
       "      <td>0.007845</td>\n",
       "      <td>0.014271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237137</th>\n",
       "      <td>1619725101980</td>\n",
       "      <td>-1.616086</td>\n",
       "      <td>9.428665</td>\n",
       "      <td>-1.491588</td>\n",
       "      <td>0.004276</td>\n",
       "      <td>0.007941</td>\n",
       "      <td>0.012217</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002394</td>\n",
       "      <td>0.009269</td>\n",
       "      <td>0.007845</td>\n",
       "      <td>0.014271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237138</th>\n",
       "      <td>1619725101990</td>\n",
       "      <td>-1.623269</td>\n",
       "      <td>9.584289</td>\n",
       "      <td>-1.762132</td>\n",
       "      <td>0.017715</td>\n",
       "      <td>0.006109</td>\n",
       "      <td>0.012828</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002394</td>\n",
       "      <td>0.009269</td>\n",
       "      <td>0.007845</td>\n",
       "      <td>0.014271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20523372 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        utcTimeMillis  UncalAccelXMps2  UncalAccelYMps2  UncalAccelZMps2  \\\n",
       "0       1589494244845         0.177860        10.159246         1.052928   \n",
       "1       1589494244847        -0.002934        10.351667         0.934190   \n",
       "2       1589494244850        -0.114138        10.099208         0.751948   \n",
       "3       1589494244853        -0.089033         9.789539         0.821809   \n",
       "4       1589494244856        -0.123533         9.586480         0.996857   \n",
       "...               ...              ...              ...              ...   \n",
       "237134  1619725101950        -1.668759         9.577106        -1.575385   \n",
       "237135  1619725101961        -1.479617         9.581895        -1.970428   \n",
       "237136  1619725101970        -1.472434         9.433454        -1.565808   \n",
       "237137  1619725101980        -1.616086         9.428665        -1.491588   \n",
       "237138  1619725101990        -1.623269         9.584289        -1.762132   \n",
       "\n",
       "        UncalGyroXRadPerSec  UncalGyroYRadPerSec  UncalGyroZRadPerSec  \\\n",
       "0                 -0.003550             0.023597            -0.082773   \n",
       "1                 -0.003370             0.030998            -0.080377   \n",
       "2                 -0.004533             0.028622            -0.074239   \n",
       "3                 -0.008254             0.017697            -0.065580   \n",
       "4                 -0.008272             0.010407            -0.058197   \n",
       "...                     ...                  ...                  ...   \n",
       "237134             0.007330             0.007941             0.010996   \n",
       "237135             0.018937             0.003665             0.013439   \n",
       "237136            -0.004887             0.011606             0.015882   \n",
       "237137             0.004276             0.007941             0.012217   \n",
       "237138             0.017715             0.006109             0.012828   \n",
       "\n",
       "        BiasXMps2  BiasYMps2  BiasZMps2  DriftXRadPerSec  DriftYRadPerSec  \\\n",
       "0             NaN        NaN        NaN              NaN              NaN   \n",
       "1             NaN        NaN        NaN              NaN              NaN   \n",
       "2             NaN        NaN        NaN              NaN              NaN   \n",
       "3             NaN        NaN        NaN              NaN              NaN   \n",
       "4             NaN        NaN        NaN              NaN              NaN   \n",
       "...           ...        ...        ...              ...              ...   \n",
       "237134        0.0        0.0  -0.002394         0.009269         0.007845   \n",
       "237135        0.0        0.0  -0.002394         0.009269         0.007845   \n",
       "237136        0.0        0.0  -0.002394         0.009269         0.007845   \n",
       "237137        0.0        0.0  -0.002394         0.009269         0.007845   \n",
       "237138        0.0        0.0  -0.002394         0.009269         0.007845   \n",
       "\n",
       "        DriftZRadPerSec  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  \n",
       "...                 ...  \n",
       "237134         0.014271  \n",
       "237135         0.014271  \n",
       "237136         0.014271  \n",
       "237137         0.014271  \n",
       "237138         0.014271  \n",
       "\n",
       "[20523372 rows x 13 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "------------------------------------\n",
    "# Exploratory Data Analysis\n",
    "### EDA on derived dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ground truth\n",
    "First of all we want to look at what we even want to predict.<br>\n",
    "Therefore we will have some vizualizations that will help us understand the ground truth dataset<br>\n",
    "and our target variables latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareRoutes(true_route, predicted_route=None, mapName='map', color='cornflowerblue'):\n",
    "    \"\"\"Recieve as input two routes one as the ground truth and the other as the predicted.\n",
    "    The ground truth would be drawn as line on the map.\n",
    "    The predicted would be drawn as heatmap.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    true_route : numpy 2d array\n",
    "        The true route the sample has went through\n",
    "    predicted_route : numpy 2d array\n",
    "        The predicted route\n",
    "    mapName : str\n",
    "        defualt = 'map'\n",
    "        The name of the generated html google map\n",
    "        \n",
    "    Output\n",
    "    ------\n",
    "    mapName.html file containing the google map.\n",
    "    \"\"\"\n",
    "    gmap1 = gmplot.GoogleMapPlotter(true_route[true_route.shape[0]//2,0], true_route[true_route.shape[0]//2,1], 14, apikey='AIzaSyB0ONxmQBgtM14DqTRDrYBBUw2-woWkCIE', map_type='hybrid')\n",
    "    gmap1.plot(true_route[:,0],true_route[:,1], color, edge_width=2)\n",
    "    if(predicted_route is not None):\n",
    "        gmap1.heatmap(predicted_route[:,0],predicted_route[:,1])\n",
    "    gmap1.draw( \"{}.html\".format(mapName) )\n",
    "    # Print the map to notebook\n",
    "    return IFrame(src=\"./{}.html\".format(mapName), width=700, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"600\"\n",
       "            src=\"./map.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2339b2c8108>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapName='map'\n",
    "plasma = matplotlib.cm.get_cmap('plasma',ground['collectionName'].nunique())\n",
    "gmap1 = gmplot.GoogleMapPlotter(true_route[true_route.shape[0]//2,0], true_route[true_route.shape[0]//2,1], 14, apikey='AIzaSyB0ONxmQBgtM14DqTRDrYBBUw2-woWkCIE', map_type='hybrid')\n",
    "for i, collection in enumerate(ground['collectionName'].unique()):\n",
    "    color = matplotlib.colors.rgb2hex(plasma.colors[i])\n",
    "    df = ground[ground['collectionName']==collection]\n",
    "    df = df[df['phoneName'] == df.iloc[0]['phoneName']]\n",
    "    true_route = np.array(df[['latDeg', 'lngDeg']])\n",
    "    gmap1.plot(true_route[:,0],true_route[:,1], color, edge_width=5)\n",
    "gmap1.draw( \"{}.html\".format(mapName) )\n",
    "# Print the map to notebook\n",
    "IFrame(src=\"./{}.html\".format(mapName), width=700, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following map protrayes the data collection traces over the bay area, as we can see most of the traces<br>\n",
    "are from the same area, there are even some traces that overlap.<br>\n",
    "this fact can help us train a model that is specificaly made for the bay area.<br>\n",
    "there are some more complex routes than others, some are on the highway while others are driving in the city.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following plot we are going to plot the collections durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='90f915fd-ee56-44ab-a4fa-d6fb16c0ec58'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0xb792b47aec8>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "df = ground.groupby('collectionName').agg({'millisSinceGpsEpoch': [('duration (minutes)', lambda x: ((np.max(x)-np.min(x))/1000)/60)]}).reset_index()\n",
    "g = sns.barplot(data=df,x=('millisSinceGpsEpoch', 'duration (minutes)'), y='collectionName')\n",
    "g.axvline(float(df.mean()), label='mean duration')\n",
    "g.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the collections are around 30 minutes of driving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets portray the change in speed over time for all the collections to have some understanding on the consistency of the speed.<br>\n",
    "the more the speed will change the harder it gets to predict the data using simple models that their main assumption is that speed won't change<br>\n",
    "therefore it can be easy for them to predict the vehicle course of action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='e54a8ce9-928b-4dae-a9e0-7415a6e324c3'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nitza\\Anaconda3\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1402: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  x[:, None]\n",
      "C:\\Users\\nitza\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:276: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  x = x[:, np.newaxis]\n",
      "C:\\Users\\nitza\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_base.py:278: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  y = y[:, np.newaxis]\n"
     ]
    }
   ],
   "source": [
    "def plotPerCollection(data, collections, features):\n",
    "    fig, ax = plt.subplots(nrows=(len(collections)//6)+1, ncols=6, sharex=True, sharey=True, figsize=(((len(collections)//6)+1)*3, 12))\n",
    "    for i in range(ax.shape[0]):\n",
    "        for j in range(ax.shape[1]):\n",
    "            df = data[data['collectionName']==collections[i*ax.shape[0]+j]]\n",
    "            df = df[df['phoneName'] == df.iloc[0]['phoneName']]\n",
    "            for feature in features:\n",
    "                ax[i][j].plot((df['millisSinceGpsEpoch']-df.iloc[0]['millisSinceGpsEpoch'])/1000, df[feature], label=feature)\n",
    "            ax[i][j].title.set_text(collections[i*ax.shape[0]+j])\n",
    "    fig.text(0.5, 0.04, 'Timestamp in seconds since the start of the collection', ha='center', size='large')\n",
    "    fig.text(0.08, 0.5, str(features)+\" features values\", va='center', rotation='vertical', size='large')\n",
    "    handles, labels = ax[i][j].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper center')\n",
    "plotPerCollection(ground, ground['collectionName'].unique(), ['speedMps'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we seen from the map indeed we have collections which have more consistent speed<br>\n",
    "due to the fact that they are simply driving a car on a highway probably without changing lanes too much.<br>\n",
    "We believe these collections will be far easier to predict with great accurracy than the ones where the speed is constantly changing.<br>\n",
    "The collections which the speed is constantly changing are related to inner city collections such as in 2021-04-22-US-SJC-1 which is a low speed measurement<br>\n",
    "but constantly the car comming to a full stop due to the multiple turns.<br>\n",
    "Later on when we will compare the baseline predictions to the ground truth we will inspect whether the speed change rate do have an effect on the performance.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        event.shiftKey = false;\n",
       "        // Send a \"J\" for go to next cell\n",
       "        event.which = 74;\n",
       "        event.keyCode = 74;\n",
       "        manager.command_mode();\n",
       "        manager.handle_keydown(event);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='3b5e3730-056e-4828-afed-9b3baec56315'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotPerCollection(ground, ground['collectionName'].unique(), ['hDop', 'vDop', 'heightAboveWgs84EllipsoidM'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When visible navigation satellites are close together in the sky, the geometry is said to be weak and the DOP value is high; when far apart, the geometry is strong and the DOP value is low.<br>\n",
    "Thus a low DOP value represents a better positional precision due to the wider angular separation between the satellites used to calculate a unit's position. Other factors that can increase the<br>effective DOP are obstructions such as nearby mountains or buildings.<br> DOP can be expressed as a number of separate measurements. HDOP, VDOP, PDOP, and TDOP are respectively Horizontal, Vertical, Position (3D), and Time Dilution of Precision.<br>\n",
    "https://www.gsat.us/support/glossary/hdop\n",
    "\n",
    "We conclude that the lower the DOP value the more precise positioning. (maybe can be used as a way to give weight to our samples)<br>\n",
    "another thing we understand is that the obsticles around us can affect the DOP values therefore we would like to plot the height which can give<br>\n",
    "us indication regarding mountainess region.\n",
    "\n",
    "As we can notice from the plot above most of the higher DOP values occurress around valleys.<br>\n",
    "a perfect example for this phenomenon is collection 2021-04-15-MTV-US-1, the hDOP value spikes whenever the vehicle reaches the bottom of the vally and is blocked by high mountains.<br>\n",
    "The same is happening at 2020-08-03-MTV-US-1 and more. It is clear that whenever the montains are blocking the GNSS signal we are getting dilution in the precision.<br>\n",
    "In the city collections the region is not blocked by montains rather by buildings therefore these spikes of DOP. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline dataframe analysis\n",
    "As we mentioned before the baseline dataframe had been generated by weighted least squares on the derived data.<br>\n",
    "we will describe later the derived data more deeply but due to it's complexisity of understanding and the need for domain knowledge we would like to<br>\n",
    "firstly talk about the baseline dataset which is far more easier to understand.\n",
    "<br><br>\n",
    "Two images that help us understand why we even need to be more accurrate with our predictions:\n",
    "![alt text](BaselineFuckesup.jpg \"under the bridge no reception\")\n",
    "it is clear from the following image that there is a huge problem with the baseline predictions.<br>\n",
    "there are some predictions that the baseline positioning us outside the road and even up on the hill as far as at least 5m from the car position.<br>\n",
    "in other data points it positioning us on the opposite lane.<br>\n",
    "![alt text](WhyWeNeedMoreAccurateGPS.jpg \"In the building\")\n",
    "In this example baseline is positioning us on the walking pavement and even on the rooftops.<br>\n",
    "very inaccurrate positioning that any application that need some more refined positioning cannot use these predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline and ground truth data are synchronized\n"
     ]
    }
   ],
   "source": [
    "bsln_trn.head(3)\n",
    "if np.all(bsln_trn.reset_index()['millisSinceGpsEpoch'] == ground.reset_index()['millisSinceGpsEpoch']):\n",
    "    print(\"Baseline and ground truth data are synchronized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can notice there is not much data in the baseline but it is exactly the prediction that is needed and our model would need to perform at least better than the baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot collection route on a map using ground truth route vs. baseline route\n",
    "The following function draws the ground truth locations on google map map and on the ground truth locations the map plots a heatmap of the frequency of the locations of baseline location predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the following map we can see the baseline predicted values vary around the ground truth<br>\n",
    "The route in blue represent the true route of the measurements while the hit map represent the baseline measurement.<br>\n",
    "The hotter the color gets, the more frequent and concentraited the predictions are.<br>\n",
    "You can interact with the map as with any google map. <br>\n",
    "Try to zoom in and have a look at the prediction distribution around the route and how it diviates from the ground truth<br>\n",
    "We can also notice why decimeter prediction is neccessary as jumpy navigation system can cause quite distress,<br>\n",
    "Especially if we finding ourself outside the road or even on the roof of some building as we can observe in multiple observations.<br>\n",
    "High accurracy navigation systems such as ADAS, Autonomous vehicles or even Pokemon GO have critical neccessity in highly accurrate lat lng positioning.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derived['collectionName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derived[derived['collectionName']=='2021-04-29-US-MTV-1']['phoneName'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def drawRandomPath(collection='random', phone='random', mapName='random'):\n",
    "    if collection == 'random':\n",
    "        collection = target['collectionName'].sample().iloc[0]\n",
    "    if phone == 'random':\n",
    "        phone = target[target['collectionName'] == collection]['phoneName'].sample().iloc[0]\n",
    "    t = target[(target['collectionName'] == collection) & (target['phoneName'] == phone)]\n",
    "    print(phone, collection)\n",
    "    return compareRoutes(np.array(t[['latDeg_grnd','lngDeg_grnd']]), np.array(t[['latDeg_bsln','lngDeg_bsln']]), mapName=mapName)\n",
    "drawRandomPath(collection='2020-09-04-US-SF-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drawRandomPath(collection='2021-04-29-US-MTV-1', phone='SamsungS20Ultra', mapName='2021-04-29-US-MTV-1-SamsungS20Ultra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drawRandomPath(collection='2021-04-29-US-MTV-1', phone='Pixel4', mapName='2021-04-29-US-MTV-1-Pixel4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we compare two devices on the same route it seems the pixel 4 is a bit more cluttered than the samsung device.<br>\n",
    "But both of them are off from the real lane for at least 2m if not more at complex turns and when the vehicle stops.<br>\n",
    "Every intersection where the vehicle stopped we can notice a big cloud of data points for both of the devices<br>\n",
    "Maybe the baseline method is more prone to error at changes in the vehicle speed and low speed traveling.<br>\n",
    "It seems that at segments of the road where the car should have constant speed it seems like the datapoints are more accurate.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_tmp = ground\n",
    "ground_tmp['acceleration'] = (ground['speedMps'] - ground['speedMps'].shift()) / (ground['millisSinceGpsEpoch'] - ground['millisSinceGpsEpoch'].shift())\n",
    "ground_tmp[ground_tmp['acceleration']>0].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what is a good performance? how do we measure it?<br>\n",
    "How can we tell that the baseline predictions are not good enough for precise navigation and accurrate positioning?<br>\n",
    "this rough comparison between the ground truth and the baseline predictions can't tell us nothing about how well the least squares mehod performed.<br>\n",
    "We need numerical evaluation for the performance of the predictions.<br>\n",
    "luckily the competition evaluation metric is provided for us<br>\n",
    "therefore we think that before we continue analysing any training data we should at least display why baseline predictions are just not good enough<br>\n",
    "and we need to get much more accurrate<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Derived dataset\n",
    "Firstly we know each sample in the derived can be comprised out of several satelites<br>\n",
    "In the process of sampling the phone tries to communicate with as many GNSS system satelites as possible for maximum accurricy.<br>\n",
    "The more the merier.<br>\n",
    "Let's count the number of satelites that had been involved in the process.<br>\n",
    "We will calculate some metrics such as the total number of samples, the mean/std/max/percentiles number of satelites per sample.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drvd_idx = derived.set_index(['collectionName','phoneName', 'millisSinceGpsEpoch'])\n",
    "print(\"The number of different satelites is: {}\".format(derived['svid'].nunique()))\n",
    "g = derived.groupby(['collectionName','phoneName', 'millisSinceGpsEpoch']).agg({'svid': [ len,lambda x: np.bincount(x).argmax()]})\n",
    "g.rename({'<lambda_0>': 'frequency', 'len': 'numOfSamples'}, axis=1, inplace=True)\n",
    "bnc = np.bincount(g[('svid', 'frequency')])\n",
    "print(\"The most frequent satelite is: {} with {} occurrences\".format(bnc.argmax(), max(bnc)))\n",
    "g.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we noticed a single sample in a collection can be made out of as many as 109 datapoints. \n",
    "There are only 37 satelites, so we need to find out the source for the multiple samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s = g[g['svid', 'numOfSamples']==g['svid','numOfSamples'].max()]\n",
    "s2 = drvd_idx[drvd_idx['svid']==s.iloc[0]['svid','frequency']].loc[s.index[0]]\n",
    "s2.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the fields are present as mentioned in the data section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From index column it is clear that we are currently inspecting 12 datapoints from single satelite at specific sample.<br>\n",
    "The unique table doesn't give out an immidiate suspect with 12 unique values, it is probably a combination of columns. <br>\n",
    "Lets try constellationType + signalType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s2['constellationSignal'] = s2['constellationType'].astype(str) + '_'+ s2['signalType']\n",
    "s2['constellationSignal'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 4 combinations for this sample therefore the  constellationType + signalType combination is not to blame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s2.groupby(s2.columns.tolist(),as_index=False).size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple datapoints with duplicate rows, but still there are 8 different rows after grouping by all columns to find the pure duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s2.groupby(['rawPrM', 'receivedSvTimeInGpsNanos', 'constellationSignal'],as_index=False).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The measurements are recieved at different timestamps and therefore the raw pseodo range is affected because of the movement of the satelite.<br>\n",
    "After dropping duplicates we still going to remain with several measurements per svid on specific sample due to multiple polling at different recieved times.<br>\n",
    "Before handeling the data we should drop the duplicate rows containing exactly the same values at every column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_derived_count = derived.shape[0]\n",
    "derived.drop_duplicates(inplace=True)\n",
    "print(\"Dropped {} duplicate measurements\".format(old_derived_count-derived.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single sample 3d visualization\n",
    "for single android measurment visualize the specific point on earth the phone exists and the connected satelites,<br>\n",
    "Exibit the velocity of every satelite and the distance from the phone measured as the corrected pseudo range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSatelite(ax, x, phone_cor=None):\n",
    "    \"\"\"Plot satelite measurements for a specific sample.\n",
    "    \"\"\"\n",
    "    ax.scatter(x['xSatPosM'], x['ySatPosM'], x['zSatPosM'], c='r',s=50)\n",
    "    ax.quiver(x['xSatPosM'], x['ySatPosM'], x['zSatPosM'], x['xSatVelMps'], x['ySatVelMps'], x['zSatVelMps'], length=(x['xSatVelMps']**2+x['ySatVelMps']**2+x['zSatVelMps']**2)**0.5)\n",
    "    if isinstance(x.name, (int, np.integer)):\n",
    "        ax.text(x['xSatPosM'], x['ySatPosM'], x['zSatPosM']+10, str(x.name))\n",
    "    if phone_cor is not None:\n",
    "        ax.plot([x['xSatPosM'], phone_cor[0]], [x['ySatPosM'], phone_cor[1]], [x['zSatPosM'], phone_cor[2]], c='g')\n",
    "        \n",
    "def plotSphere(ax, r=6731000, center=(0,0,0), hRange=(0, 2 * np.pi), vRange=(0, np.pi), phoneLat=0, phoneLng=0):\n",
    "    theta = np.array([np.linspace(hRange[0], hRange[1], 50)])\n",
    "    theta = np.ones_like(theta).T @ theta\n",
    "    phi = np.array([np.linspace(vRange[0], vRange[1], 50)])\n",
    "    phi = np.ones_like(phi).T @ phi\n",
    "    phi = phi.T\n",
    "    \n",
    "    xx = r * np.sin(phi) * np.cos(theta) + center[0]\n",
    "    yy = r * np.sin(phi) * np.sin(theta) + center[1]\n",
    "    zz = r * np.cos(phi) + center[2]\n",
    "    \n",
    "    ax.plot_surface(xx, yy,zz)\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "def latlonToXYZ(lat, lon):\n",
    "    r=6731000 # Earth radius\n",
    "    return (float(r * np.sin(lat) * np.cos(lon)), float(r * np.sin(lat) * np.sin(lon)), float(r * np.cos(lat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derived.reset_index(inplace=True)\n",
    "ground.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Index of every sample is attributed to the collection, the phone used in the collection set <br>(The data is collected using multiple android phones in driving car)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derived['millisSinceGpsEpoch_drvd'] = derived['millisSinceGpsEpoch']\n",
    "derived_idx = derived.set_index(['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'svid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Choose random sample from derived data to display satelites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot tries to sums up a single measurement in the derived dataset.<br>\n",
    "The blue sphere represent the earth.<br>\n",
    "The pink dot represents the north pole.<br>\n",
    "The green dot represents the android device making the measurement.<br>\n",
    "Each red dot represents a satelite in space.<br>\n",
    "Each satelite has vector representing its speed.<br>\n",
    "Each satelite streches a line in green which represents the distance to the the android device.<br>\n",
    "All the locations are appearing in ECEF coordinated system, with earth fixed in the center (the axis are the ECEF coordinated system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "ax.scatter(derived['xSatPosM'],derived['ySatPosM'],derived['zSatPosM'], c=derived['svid'], s=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.figure().add_subplot(projection='3d')\n",
    "plotSphere(ax)\n",
    "north_pole = latlonToXYZ(90, 0)\n",
    "ax.scatter(north_pole[0],north_pole[1],north_pole[2], c='pink', s=100)\n",
    "\n",
    "sample = derived[['collectionName', 'phoneName', 'millisSinceGpsEpoch']].sample()\n",
    "while not np.any(ground['millisSinceGpsEpoch']==sample.values[0,2]):\n",
    "    sample = derived[['collectionName', 'phoneName', 'millisSinceGpsEpoch']].sample()\n",
    "sample_target = ground[ground['millisSinceGpsEpoch']==sample.values[0,2]]\n",
    "\n",
    "plt.title(\"collectionName: {}  || Phone: {} ||  timestamp: {} ms\".format(sample.values[0,0], sample.values[0,1], sample.values[0,2]))\n",
    "satelites = derived_idx.loc[sample.values[0,0], sample.values[0,1], sample.values[0,2]]\n",
    "phone_cor = latlonToXYZ(sample_target['latDeg'], sample_target['lngDeg'])\n",
    "satelites.apply(lambda sat: plotSatelite(ax, sat, phone_cor), axis=1)\n",
    "ax.scatter(phone_cor[0],phone_cor[1],phone_cor[2], c='g', s=100)\n",
    "\n",
    "ax.text(phone_cor[0]+1000,phone_cor[1]+1000,phone_cor[2]+1000, \"lat:{}, lng:{}\".format(float(sample_target['latDeg'],), float(sample_target['lngDeg'])))\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose a specific collection and plot the collection's connection with different satelites.<br>\n",
    "The plot would be consisted of several line plots one for each satelite, on the x axis the epoch,<br>\n",
    "on the y axis the pseodo range (the distance from the satelite and the phone device) and we will try and correlate this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = derived[['collectionName', 'phoneName']].sample()\n",
    "df = derived.set_index(['collectionName', 'phoneName', 'millisSinceGpsEpoch']).loc[sample.values[0,0], sample.values[0,1]]\n",
    "df.reset_index(inplace=True)\n",
    "df['rawPrM_norm'] = (df['rawPrM']-df['rawPrM'].min())/(df['rawPrM'].max()-df['rawPrM'].min())\n",
    "df['millisSinceGpsEpoch'] = (df['millisSinceGpsEpoch']-df['millisSinceGpsEpoch'].min())/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "sns.scatterplot(data=d.sort_values('millisSinceGpsEpoch'), x='millisSinceGpsEpoch', y='rawPrM', hue='svid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ground truth vs. derived `millisSinceGpsEpoch` comparison\n",
    "In order to further invistigate the relations between the derived data and the ground truth we will need to make sure these two datasets are synchronized.<br>\n",
    "The following code will check whether the number of epochs is the derived dataset is correlated with the no. of epochs at ground truth dataset.<br>\n",
    "Next we will check if the two datasets are aligned with each other.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if derived['millisSinceGpsEpoch'].nunique() == ground['millisSinceGpsEpoch'].nunique():\n",
    "    print(\"Derived and ground truth data has the same number of time ephocs\")\n",
    "    if np.all(derived['millisSinceGpsEpoch'] == ground['millisSinceGpsEpoch']):\n",
    "        print(\"Derived and ground truth data are synchronized\")\n",
    "    else:\n",
    "        print(\"Derived and ground truth data are not synchronized\")\n",
    "else:\n",
    "    print(\"Derived and ground truth data has different number of time ephocs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The baseline and derived are correlated. moreover baseline is genrated using derived dataset\n",
    "* It seems that unfortunatly there is a difference between the timestamp of the samples in the ground truth\n",
    "  and the baseline as shown in the following. there are some samples that are the same regarding the timestamp and others which not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at how the number of samples are distributed over the ground truth dataset determined by the different collections.<br>\n",
    "Then we will try and compare it to the derived data set distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,15))\n",
    "ax = fig.gca()\n",
    "sns.countplot(data=ground, y='collectionName', hue='phoneName', ax=ax, palette='rocket')\n",
    "ax.legend(loc='upper right')\n",
    "ax.yaxis.grid(True)\n",
    "plt.title('Ground truth number of samples per collection')\n",
    "fig = plt.figure(figsize=(8,15))\n",
    "ax = fig.gca()\n",
    "sns.countplot(data=derived, y='collectionName', hue='phoneName', ax=ax, palette='rocket')\n",
    "ax.legend(loc='upper right')\n",
    "ax.yaxis.grid(True)\n",
    "plt.title('Derived number of samples per collection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following chart we can see the distribution of number of rows at each collection over the dataset split by phoneName.<br>\n",
    "On the upper chart we displayed the ground truth no. of samples and on the botton is the derived data.<br>\n",
    "The horizontal axis represent the number of rows in the dataframes, the vertical axis is the collection name and the color represent the phone.<br>\n",
    "We can notice right away few interesting things.<br>\n",
    "<br>\n",
    "Firstly derived collections contains a lot more data than the ground truth, which got us to think on the need to aggregate in the proper manner the measurements in order to archieve our target.<br>\n",
    "The reasonably look at the same proportions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code block will setup the constellation type mapping from the metadata for ease of chart reading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "constellations = pd.read_csv('./google-smartphone-decimeter-challenge/metadata/constellation_type_mapping.csv')\n",
    "derived = derived.merge(constellations, on='constellationType', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following chart would display several features  frequency disributions over pie charts.<br>\n",
    "We chose to display the disribution of the phoneName, the signal type that has been recieved and the constellationType of the recieved satelite signals.<br>\n",
    "The mobile device type distribution over test and train collections is identical as is aserted and displayed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pieplot_on_columns(data, columns):\n",
    "    for c in columns:\n",
    "        data_dist = data.groupby(c).size().to_frame('size')\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.title.set_text(f'{c} distribution by # of samples')\n",
    "        ax.pie(data_dist['size'], labels=list(data_dist.index), autopct=lambda x: f'{int(x)}%')\n",
    "        plt.show()\n",
    "\n",
    "pieplot_on_columns(derived, ['phoneName', 'signalType', 'constellationName'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The vast majority of collections had been done using google's pixel4 phone.\n",
    "2. As expected the dominant constilationType is GPS in the US but the majority of samples actually come from non US systems such as GALILEO (europe), GLONASS(Russia),<br>\n",
    "Beidu and QZSS has small presence due to the fact that they are local systems that operates only in east asia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following figure we are displaying a heatmap of the number of samples per satelite for each collection<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = derived[['collectionName', 'svid', 'millisSinceGpsEpoch']].groupby(['collectionName', 'svid']).count()\n",
    "d.reset_index(inplace=True)\n",
    "d = d.pivot_table(columns='svid', values='millisSinceGpsEpoch', index='collectionName', fill_value=0)\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "ax = fig.gca()\n",
    "sns.heatmap(data=d, ax=ax)\n",
    "plt.title(\"Collection to satelite number of samples heatmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vertical axis is the name of the collection, the horizontal axis is the satelite id.<br>\n",
    "The brighter the square is the more frequent the satelite is in the specific collection.<br>\n",
    "We can notice the busier satelites are svid: 2, 27, 30.<br>\n",
    "But we cannot jump to conclusions from this chart due to the fact that not every collection has been executed for the same time duration.<br>\n",
    "the longer the collection is the more samples are and the more important it would look on the heatmap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plots display the distribution of the X/Y/Z positions & velocity in the ECEF axis.<br>\n",
    "the distribution of ionic sphere and tropo sphere delay in the samples.<br>\n",
    "Another interesting feature we are looking at is the distribution of raw pseodo range.<br>\n",
    "this represent the distribution of how far the satelites are from the android device.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot constellation types\n",
    "# plot signal types\n",
    "# understand if all derived samples (key samples contain each of which signals and constellations)\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.set_size_inches(8, 8, forward=True)\n",
    "sns.boxplot(x='variable', y='value', data=pd.melt(derived[['xSatPosM', 'ySatPosM', 'zSatPosM']]), ax = axs[0][0])\n",
    "sns.boxplot(x='variable', y='value', data=pd.melt(derived[['xSatVelMps', 'ySatVelMps', 'zSatVelMps']]), ax = axs[0][1])\n",
    "sns.boxplot(x='variable', y='value', data=pd.melt(derived[['ionoDelayM', 'tropoDelayM']]), ax = axs[1][0])\n",
    "sns.boxplot(data=pd.melt(derived[['rawPrM']]), x='variable',  y='value', ax= axs[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance from the satelites stays mostly betwween 2.2e7 to 2.5e7 with few outliers to the upper bound.<br>\n",
    "therefore we probably will need to notice more subtle changes to predict accurratly the location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's explore how the GNSS derived data correlates to the ground truth via dimensionality reducation.\n",
    "We will apply dimentionality reduction for better vizualizing our features and how they behave in comparison to the target vairables.<br>\n",
    "Due to the multidimentunal target variables we would try to reduce the dimension of the target variables and the heightAboveWgs84EllipsoidM to 1 dimension.<br>\n",
    "Secondly we would reduce selected features from derived data to 1 dimension<br>\n",
    "Finally we would plot the data on 2d axis for vizualizing the data.<br>\n",
    "We will perform the dimensionality reduction using Principal component analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for ground truth and derived data correlation we will try to merge the two into one dataframe.<br>\n",
    "the problem is that ground truth has less than half the amount of rows that derived dataset has.<br>\n",
    "another problem from a glance at the two frames is that derived sometimes has a deviation of 1 millisecond from<br>\n",
    "the ground truth sample time. We believe it is due to rounding error and therefore can be dissmissed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grnd = ground.set_index(['collectionName', 'phoneName', 'millisSinceGpsEpoch'])\n",
    "drvd = derived.set_index(['collectionName', 'phoneName', 'millisSinceGpsEpoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drvd.loc[('2021-04-29-US-MTV-1', 'SamsungS20Ultra')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grnd.loc[('2021-04-29-US-MTV-1', 'SamsungS20Ultra')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we suspected for a simple collection there are more than x46 rows at derived and the epochs are mostly off by 1 millisecond.<br>\n",
    "to fix this problem when we use merge we will use more flexible merge function that will have a tolerence of 1 millisecond forward that 1303770562999 will be the same as 1303770563000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drvdGrnd = pd.merge_asof(derived.sort_values('millisSinceGpsEpoch'), ground.sort_values('millisSinceGpsEpoch'), on='millisSinceGpsEpoch',\n",
    "              suffixes=['_drvd', '_grnd'], tolerance=1, by=['collectionName', 'phoneName'], direction='forward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how much missing values exists in our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drvdGrnd.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "150 rows only in the ground truth columns, probably due to bigger deviation in the millisSinceGpsEpoch.<br>\n",
    "due to the low rate of missing values we can simply discard them in order to calculate PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drvdGrnd.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better results before performing PCA it is usually recommended to perform normalization on the data.<br>\n",
    "We will use sklearn StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler_y = StandardScaler()\n",
    "scaler_y.fit(drvdGrnd[['latDeg', 'lngDeg', 'heightAboveWgs84EllipsoidM', 'courseDegree', 'speedMps']])\n",
    "drvdGrnd_normed_y = scaler_y.transform(drvdGrnd[['latDeg', 'lngDeg', 'heightAboveWgs84EllipsoidM', 'courseDegree', 'speedMps']])\n",
    "\n",
    "scaler_x = StandardScaler()\n",
    "scaler_x.fit(drvdGrnd[['xSatPosM', 'ySatPosM', 'zSatPosM', 'xSatVelMps', 'ySatVelMps', 'zSatVelMps', 'ionoDelayM', 'tropoDelayM', 'rawPrM', 'rawPrUncM', 'isrbM']])\n",
    "drvdGrnd_normed_x = scaler_x.transform(drvdGrnd[['xSatPosM', 'ySatPosM', 'zSatPosM', 'xSatVelMps', 'ySatVelMps', 'zSatVelMps', 'ionoDelayM', 'tropoDelayM', 'rawPrM', 'rawPrUncM', 'isrbM']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_y = PCA(n_components=1) \n",
    "y_transformed = pca_y.fit_transform(drvdGrnd_normed_y) \n",
    "pca_x = PCA(n_components=1) \n",
    "x_transformed = pca_x.fit_transform(drvdGrnd_normed_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(x=x_transformed, y = y_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on the horizontal axis the derived data principal component of 1 component is set.<br>\n",
    "on the vertical axis the ground truth data principal component of 1 component is set.<br>\n",
    "As you can see it is a big mesh of a plot with no actual value for us beside that it looks kind of squarish?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the derived data it seems that at least for us it would be very hard to archive some kind of location calculation function without any previous domain knowledge in this field<br>\n",
    "Therefore we will try to firstly test how can we perform on much more simpler dataset, baseline, that contains already aggregated features.<br>\n",
    "The baseline can actually be our guideline and our model will just incorperate multiple samples and take better predictions that make small but accurate deviation from the baseline.<br>\n",
    "Later on we can try to incorprate the derived data but due to the fact that we don't know how to calculate lat/lon data from this raw measurements<br>\n",
    "maybe it would be best to simply use neural network to calculate it for us.<br>\n",
    "\n",
    "First of all we must explore the baseline dataframe to know how get around with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the evaluation metric\n",
    "The challenge evaluation metric is set to be as following:<br>\n",
    "https://www.kaggle.com/c/google-smartphone-decimeter-challenge/overview/evaluation<br>\n",
    "Submissions are scored on the mean of the 50th and 95th percentile distance errors. For every phone and at every millisSinceGpsEpoch,<br> the horizontal distance (in meters) is computed between the predicted lat/lng and the ground truth lat/lng.<br> These distance errors form a distribution from which the 50th and 95th percentile errors are calculated (i.e. the 95th percentile error is the value, in meters, for which 95% of the distance errors are smaller).<br> The 50th and 95th percentile errors are then averaged for each phone.<br> Lastly, the mean of these averaged values is calculated across all phones in the test set.<br><br>\n",
    "\n",
    "https://en.wikipedia.org/wiki/Haversine_formula\n",
    "\n",
    "The harversine function determines the \"Great circle\" distance between 2 latlon datapoints.<br>\n",
    "We are using this measurement to accurratly determine as needed the `horizontal distance` between two points on earth.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculates the great circle distance between two points\n",
    "    on the earth. Inputs are array-like and specified in decimal degrees.\n",
    "    \"\"\"\n",
    "    RADIUS = 6_367_000\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2)**2 + \\\n",
    "        np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2)**2\n",
    "    dist = 2 * RADIUS * np.arcsin(a**0.5)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The competition metric that is required is calculating the distances between the true and predicted values.<br>\n",
    "Then return the mean of the median and 95th percentile out of that distance vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def haversine_50thP_95thP_mean(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Using calc_haversine formula to calculate the mean of  the mean of the 50th and 95th percentile distance errors\n",
    "    The Competition evaluation metric\n",
    "    \"\"\"\n",
    "    haversine = calc_haversine(lat1, lon1, lat2, lon2)\n",
    "    return (np.percentile(haversine, 95) + np.median(haversine)) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are set to go with already predicted dataset of samples.<br>\n",
    "What is so bad with the initial predictions that we even need to make an effort to minimize its error?<br>\n",
    "Let's have a look at the competition evaluation for the given predictions and try to asses how they differ from the ground truth.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_prev = haversine_50thP_95thP_mean(target['latDeg_grnd'], target['lngDeg_grnd'], target['latDeg_bsln'], target['lngDeg_bsln'])\n",
    "print(\"{}m is the mean of the meadian error and the 95th percentile\".format(score_prev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As implied in the compition name 6.2 meters is simply not enough.<br>\n",
    "we have to reduce the prediction error to at least under 1m to get into the decimeter realm.<br>\n",
    "6 meters doesn't seem to be that far but soon we would see it is not an easy task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the haversine calculation we can compare the baseline estimated coordinates to the ground truth, sliced by various columns. Thus we might get an intuition for more and less \"accurate\" features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drvd_grnd_match = pd.merge_asof(derived.sort_values('millisSinceGpsEpoch'), ground.sort_values('millisSinceGpsEpoch'), on='millisSinceGpsEpoch',\n",
    "              suffixes=['_drvd', '_grnd'], tolerance=1)\n",
    "drvd_grnd_bsln = pd.merge_asof(drvd_grnd_match, bsln_trn.sort_values('millisSinceGpsEpoch'), on='millisSinceGpsEpoch',\n",
    "                              suffixes=['','_bsln'], tolerance=1)\n",
    "\n",
    "drvd_grnd_bsln['hvr_dist'] = calc_haversine(drvd_grnd_bsln.latDeg, drvd_grnd_bsln.lngDeg, drvd_grnd_bsln.latDeg_bsln, drvd_grnd_bsln.lngDeg_bsln)\n",
    "\n",
    "def evaluate_from_dist(hvr_dist):\n",
    "    return (np.nanpercentile(hvr_dist, 95) + np.nanmedian(hvr_dist)) / 2\n",
    "\n",
    "cltn_hvr_dist = drvd_grnd_bsln.groupby('collectionName')['hvr_dist'].agg(evaluate_from_dist).reset_index()\n",
    "phone_hvr_dist = drvd_grnd_bsln.groupby('phoneName')['hvr_dist'].agg(evaluate_from_dist).reset_index()\n",
    "sig_type_hvr_dist = drvd_grnd_bsln.groupby('signalType')['hvr_dist'].agg(evaluate_from_dist).reset_index()\n",
    "svid_hvr_dist = drvd_grnd_bsln.groupby('svid')['hvr_dist'].agg(evaluate_from_dist).reset_index()\n",
    "fig, axs = plt.subplots(2, 2)\n",
    "fig.set_size_inches(18, 11, forward=True)\n",
    "axs[0][0].set_title('collections compared with the haversine distance their samples produce')\n",
    "sns.barplot(x='hvr_dist', y='collectionName', data=cltn_hvr_dist, ax=axs[0][0])\n",
    "axs[0][1].title.set_text('Phone names compared with the haversine distance their samples produce')\n",
    "sns.barplot(x='hvr_dist', y='phoneName', data=phone_hvr_dist, ax=axs[0][1])\n",
    "axs[1][0].title.set_text('Signal types compared with the haversine distance that samples of that type produce')\n",
    "sns.barplot(x='hvr_dist', y='signalType', data=sig_type_hvr_dist, ax=axs[1][0])\n",
    "axs[1][1].title.set_text('Satelite ID compared with the haversine distance that its samples produce')\n",
    "sns.barplot(y='hvr_dist', x='svid', data=svid_hvr_dist, ax=axs[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An interesting outcome! Some features yield a greater deviation in haversine distance values. <br>We can immidiatly learn about two very problematic collections.<br>\n",
    "`2021-04-22-US-SJC-1` and `2021-04-29-US-SJC-2`, could it be harder to predict in San Jose? <br>\n",
    "- Another interesting finding is the error score of `SamsungS20Ultra` which is by far much more worst than the other phones.<br>\n",
    "- Phones using BeiDu (Chinese) signalType are experiencing slightly worst GNSS performance<br>\n",
    "- Satelites 34 & 37 are noticably worst performers than the rest of the bunch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline vs. ground truth spatial comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to analyze how the baseline predictions are positioned in comparison to the true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target['bsln_grnd_distance'] = calc_haversine(target['latDeg_grnd'], target['lngDeg_grnd'], target['latDeg_bsln'], target['lngDeg_bsln'])\n",
    "plt.figure()\n",
    "plt.plot(range(target.shape[0]), target['bsln_grnd_distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target['bsln_grnd_distance'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the error is quite large using simply the baseline data (Weighted Least Squars on derived data).<br>\n",
    "Further more we have some very strange outlier measurements that with very large errors that are unacceptable at any circumstances and do not even imply on simple GPS accurracy.<br> These outlier samples can range all the way from 40m error to 8km error.<br> In the future we would use outlier detection algorithm to detect these samples and then clean them.<br>\n",
    "\n",
    "Our mission is to flat that plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colors = (target['bsln_grnd_distance']<0.5).apply(lambda x: 'g' if x else 'r')\n",
    "size = (target['bsln_grnd_distance']<0.5).apply(lambda x: 2 if x else 1)\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(121); plt.title('Baseline vs. ground truth latDeg'); \n",
    "plt.scatter(target['latDeg_grnd'], target['latDeg_bsln'], color=colors, s=size)\n",
    "plt.xlabel('ground truth latDeg'); plt.ylabel('baseline latDeg')\n",
    "plt.subplot(122); plt.title('Baseline vs. ground truth lngDeg');\n",
    "plt.scatter(target['lngDeg_grnd'], target['lngDeg_bsln'], color=colors, s=size)\n",
    "plt.xlabel('ground truth lngDeg'); plt.ylabel('baseline lngDeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following figure we can see two plots. One for latDeg and the other for lngDeg.<br>\n",
    "Although it seems like a line it is a scatter plot, each point would be colored in green if the horizontal distance<br>\n",
    "from baseline prediction is lower than 5 decimeters otherwise in red. our ambision is to make transform the plot to green line that corripond to the y=x line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.all(bsln_trn.reset_index()['millisSinceGpsEpoch'] == ground.reset_index()['millisSinceGpsEpoch']):\n",
    "    print(\"Baseline and ground truth data are synchronized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kalman filter\n",
    "The kalman filter is a method to smooth estimated measurements using its noise.<br>\n",
    "The filter works iterativly on timeseries data, at each epoch the `Kalman Gain` is calculated `KG = ERR_EST / (ERR_EST + ERR_MEA)`,<br> whereas `ERR_EST` represent the error in the estimation and `ERR_MEA` represent the error in the measurement.<br>\n",
    "Then the new estimated position is calculated using The following equation `EST_t-1 + KG(EST_t - EST_t-1)` <br>\n",
    "then the new error in the estimation is calculated using `(1-KG)ERR_MEA`.<br>\n",
    "This set of iterativly equations will determine the weight to give to each estimation over time and will smooth out the estimations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phone_col = 'phonePath'\n",
    "bsln_trn[phone_col] = bsln_trn['collectionName'] + bsln_trn['phoneName']\n",
    "lat_col = 'latDeg'\n",
    "lon_col = 'lngDeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T = 1.0\n",
    "state_transition = np.array([[1, 0, T, 0, 0.5 * T ** 2, 0], [0, 1, 0, T, 0, 0.5 * T ** 2], [0, 0, 1, 0, T, 0],\n",
    "                             [0, 0, 0, 1, 0, T], [0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1]])\n",
    "process_noise = np.diag([1e-5, 1e-5, 5e-6, 5e-6, 1e-6, 1e-6]) + np.ones((6, 6)) * 1e-9\n",
    "observation_model = np.array([[1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0]])\n",
    "observation_noise = np.diag([5e-5, 5e-5]) + np.ones((2, 2)) * 1e-9\n",
    "\n",
    "kf = simdkalman.KalmanFilter(\n",
    "        state_transition = state_transition,\n",
    "        process_noise = process_noise,\n",
    "        observation_model = observation_model,\n",
    "        observation_noise = observation_noise)\n",
    "\n",
    "def apply_kf_smoothing(df, kf_=kf):\n",
    "    unique_paths = df[phone_col].unique()\n",
    "    for phone in tqdm(unique_paths):\n",
    "        data = df.loc[df[phone_col] == phone][[lat_col, lon_col]].values\n",
    "        data = data.reshape(1, len(data), 2)\n",
    "        smoothed = kf_.smooth(data)\n",
    "        df.loc[df[phone_col] == phone, lat_col] = smoothed.states.mean[0, :, 0]\n",
    "        df.loc[df[phone_col] == phone, lon_col] = smoothed.states.mean[0, :, 1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bsln_trn_orig = bsln_trn.copy()\n",
    "bsln_trn_sm = apply_kf_smoothing(bsln_trn)\n",
    "target['bsln_grnd_kalman'] = calc_haversine(ground['latDeg'], ground['lngDeg'], bsln_trn['latDeg'], bsln_trn['lngDeg'])\n",
    "target[['bsln_grnd_kalman', 'bsln_grnd_distance']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few things we notice right away is that the standard diviation decreased significantly by half.<br>\n",
    "Meaning our data is now much less noisy and jumpy, <br>\n",
    "The maximum value had reduced it's error to by more than 70% while the minimum value had been raised quite sharply by 600%.<br>\n",
    "All the other metrics had been benifited from the kalman smoothing which decreased the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(target.shape[0]), target['bsln_grnd_distance'], label='raw estimates', alpha=0.7);\n",
    "plt.plot(range(target.shape[0]), target['bsln_grnd_kalman'], label='kalman smoothed', alpha=0.7); \n",
    "plt.title('Smoothed baseline estimates using kalman filter'); \n",
    "plt.xlabel('no. sample'); \n",
    "plt.ylabel('horizontal distance (m)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice some of our highst peaks in the error distance had been lowered.<br>\n",
    "Overall nice smooth action which flatted out some jittery predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_curr = haversine_50thP_95thP_mean(ground['latDeg'], ground['lngDeg'], bsln_trn['latDeg'], bsln_trn['lngDeg'])\n",
    "print(\"{}m error rate from our evaluation metric.\\n an impovement of {}m\".format(score_curr, score_prev-score_curr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An improvement of 0.77m simply by using kalman filter with basic hyperparameters.<br>\n",
    "In the future we would like to tune the kalman filter hyperparameters for better results and even incorprate measurements from other devices like accelometer and gyro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean latDeg & lngDeg in baseline dataset over phones at the same epoch\n",
    "Each collection is made by driving car using one or more androind deviced to collect GNSS logs.<br>\n",
    "At each epoch several devices can collect GNSS data. Each of them should have the same lat/lng position<br>\n",
    "Therefore we would average over the devices the lat lng degrees.<br>\n",
    "As we can see not all the phones in our collections are synchronyzed.<br>\n",
    "Therefore we would like to mean the bucket of quarter of the seconds of epochs to leave some space for unsynchronized phones to average themeself.<br>\n",
    "The choice of 250 milliseconds was made by trial and error.<br>\n",
    "When averaging the prediction we use the assumption that the speed between each 250ms bucket is at max 65 mph (California highway speed limit) which between each bucket leave room for 3.6m error after averaging. most of the driving in the dataset is <br>made within the city, with a presumably much lower average speed so the error is much less critical.<br> Further invistagation regarding the speed at which the samples where taken will be introduced later in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bsln_trn['qsSinceGpsEpoch'] = bsln_trn.millisSinceGpsEpoch//250\n",
    "bsln_trn['millisSinceFirstEpoch'] = bsln_trn.millisSinceGpsEpoch - min(bsln_trn.millisSinceGpsEpoch)\n",
    "\n",
    "df = bsln_trn.groupby(['collectionName', 'qsSinceGpsEpoch']).agg({'latDeg': [ np.mean ], 'lngDeg': [ np.mean ], 'phoneName': [list], 'millisSinceFirstEpoch': [list]})\n",
    "bsln_mean_smoothed = pd.merge(bsln_trn, df.reset_index(), how='left', on=['collectionName', 'qsSinceGpsEpoch'], suffixes=('raw', 'mean'))\n",
    "score_prev = score_curr\n",
    "score_curr = haversine_50thP_95thP_mean(target['latDeg_grnd'], target['lngDeg_grnd'], bsln_mean_smoothed[('latDeg','mean')], bsln_mean_smoothed[('lngDeg','mean')])\n",
    "print(\"{}m error rate from our evaluation metric.\\n an impovement of {}m\".format(score_curr, score_prev-score_curr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An improvement of 2.7 decimeters, not much but still not bad for simply avrage the different phones measurements over one sample.<br> It gets us to an error of 5.21m even before applying any ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target['bsln_grnd_kalman_mean_smooth'] = calc_haversine(target['latDeg_grnd'], target['lngDeg_grnd'], bsln_mean_smoothed[('latDeg','mean')], bsln_mean_smoothed[('lngDeg','mean')])\n",
    "target[['bsln_grnd_kalman_mean_smooth', 'bsln_grnd_kalman', 'bsln_grnd_distance']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All metrics look a bit better for our smoothed version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(range(target.shape[0]), target['bsln_grnd_distance'], label='raw estimates', alpha=0.7);\n",
    "plt.plot(range(target.shape[0]), target['bsln_grnd_kalman'], label='kalman smoothed', alpha=0.7);\n",
    "plt.plot(range(target.shape[0]), target['bsln_grnd_kalman_mean_smooth'], label='kalman + mean smoothed', alpha=0.7);\n",
    "plt.title('Smoothed baseline estimates using kalman filter + mean phone average'); \n",
    "plt.xlabel('no. sample'); \n",
    "plt.ylabel('horizontal distance (m)')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some smaller peaks had been smoothed. some had been lowered down, while some more accurate measurements had been pulled upwards<br>\n",
    "Overall it seems much better than the raw baseline measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bsln_trn = bsln_mean_smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target['latDeg_bsln'] = bsln_trn['latDeg']\n",
    "target['lngDeg_bsln'] = bsln_trn['lngDeg']\n",
    "drawRandomPath()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering & data preperation\n",
    "\n",
    "* Clean the data from unwanted values\n",
    "* Generate added value features that can benefit our module.\n",
    "* Prepare the data for training and prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate corrected pseudo range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these derived values, a corrected pseudorange (i.e. a closer approximation to the geometric range from the phone to the satellite) can be computed as: correctedPrM = rawPrM + satClkBiasM - isrbM - ionoDelayM - tropoDelayM. The baseline locations are computed using correctedPrM and the satellite positions, using a standard Weighted Least Squares (WLS) solver, with the phone's position (x, y, z), clock bias (t), and isrbM for each unique signal type as states for each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "derived['correctedPrM'] = derived['rawPrM'] + derived['satClkBiasM'] - derived['isrbM'] - derived['ionoDelayM'] -derived['tropoDelayM']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Foreach sample take the previous location of the phone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As timeseries nature of the collection it is expected to give our previous estimation weight in our current estimation calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsln_trn['latDeg_prv'] = bsln_trn['latDeg']\n",
    "bsln_trn['lngDeg_prv'] = bsln_trn['lngDeg']\n",
    "bsln_trn.loc[bsln_trn['collectionName']==bsln_trn.shift()['collectionName'], 'latDeg_prv'] = bsln_trn.shift()['latDeg']\n",
    "bsln_trn.loc[bsln_trn['collectionName']==bsln_trn.shift()['collectionName'], 'latDeg_prv'] = bsln_trn.shift()['lngDeg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Add datetime timestamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the ease of analysis create timestamp columns which are much more human readable than `millisSinceGpsEpoch`<br>\n",
    "note - `millisSinceGpsEpoch` is the milliseconds passed since 6th Jan 1980"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseTime = datetime.datetime(1980,1,6,0,0,0,0)\n",
    "derived['epoch_timestamp'] = derived['millisSinceGpsEpoch'].apply(lambda x: datetime.datetime.fromtimestamp(baseTime.timestamp()+x/1000.0))\n",
    "ground['epoch_timestamp'] = ground['millisSinceGpsEpoch'].apply(lambda x: datetime.datetime.fromtimestamp(baseTime.timestamp()+x/1000.0))\n",
    "bsln_trn['epoch_timestamp'] = bsln_trn['millisSinceGpsEpoch'].apply(lambda x: datetime.datetime.fromtimestamp(baseTime.timestamp()+x/1000.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make use of the derived dataset we will narrow it down to collection-phone-epoch samples which each samples contains the relative <br>\n",
    "information regarding each satelite in the sample. If the satelite is not appearing in the current measurement all it's fields would <br>\n",
    "There are usually more than 1 sample per specific `collectionName`-`phoneName`-`millisSinceGpsEpoch`-`svid` therefore we will<br> groupby this key and use mean on our numric features before using pivot table.<br>\n",
    "correspondedly be equal to NaN. We cannot simply use 0 as our distance from them and wrap it up with `fillna(0)` <br>\n",
    "We would have to find a way to make our model ignore these values, because there is no such thing as minus distance from earth <br>\n",
    "We will assign NaN distances with `-max(correctedPrM)` to make sure our module is encourged to diffrentiate it from the true measurements and ignore it<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {'correctedPrM', 'xSatPosM', 'ySatPosM', 'zSatPosM', 'constellationType', 'xSatVelMps', 'ySatVelMps', 'zSatVelMps', 'satClkBiasM', 'satClkDriftMps'  }\n",
    "df = derived[list(features.union({'collectionName', 'phoneName', 'millisSinceGpsEpoch', 'svid'}))].groupby(['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'svid']).mean()\n",
    "piv = df.pivot_table(values=list(features), index=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], columns=['svid'])\n",
    "grouped = derived[['phoneName','collectionName', 'millisSinceGpsEpoch', 'receivedSvTimeInGpsNanos', 'epoch_timestamp']].groupby(['phoneName', 'millisSinceGpsEpoch']).max()\n",
    "piv = piv.merge(grouped, on=['phoneName', 'millisSinceGpsEpoch'])\n",
    "piv.fillna(-max(derived['correctedPrM']), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try and correlate the derived data to the ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we seen before, the number of derived epochs is different that the number of epoch is ground truth dataset. <br>\n",
    "This is a huge problem because we need to correlate the target data to the training data. <br>\n",
    "Our main objective is to predict accurratly the lat/lng position of the phone in the world using the derived data and baseline data.\n",
    "<br>\n",
    "One obsticle in doing so is that the derived dataset grouped by time epochs does not necesseraly own the same time epochs as baseline.<br>\n",
    "This problem reoccurres again when trying to compare to the target data.<br>\n",
    "So before we even do any training we need to figure out the cause for this incosistency. Or at least when does it occurres and at which scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bsln_trn['epoch_timestamp'] = bsln_trn['millisSinceGpsEpoch'].apply(lambda x: datetime.datetime.fromtimestamp(baseTime.timestamp()+x/1000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsln = bsln_trn.set_index('millisSinceGpsEpoch').sort_index()\n",
    "piv = piv.reset_index().set_index('millisSinceGpsEpoch').sort_index()\n",
    "df = pd.merge_asof(bsln, piv, on='millisSinceGpsEpoch',by='phoneName', suffixes=('_bsln', '_piv'), direction='nearest', tolerance=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. of rows that are outside the tolerance range are {}.\\nThere are total {} samples\".format(df['epoch_timestamp_piv'].isna().sum(), df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsln_trn.shape[0]-piv.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{}% of the baseline is missing from derived\".format((df['epoch_timestamp_piv'].isna().sum()/df.shape[0])*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we noticed before the derived data has 1003 missing records from baseline.<br>\n",
    "Therefore we can be satisfied with 1013 missing which is a very small percentage of the data.<br>\n",
    "nethertheless it is still part of the data and we should decide what to do next with our null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(df, ground[['phoneName', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg']], how='inner', left_on=['phoneName', 'millisSinceGpsEpoch'], right_on=['phoneName','millisSinceGpsEpoch'], suffixes=('_bsln', '_grnd'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------\n",
    "## Prepare data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = data[['latDeg_grnd', 'lngDeg_grnd']]\n",
    "\n",
    "bsln_train = bsln_trn[['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'phone', 'latDeg', 'lngDeg','latDeg_prv', 'lngDeg_prv', 'heightAboveWgs84EllipsoidM']]\n",
    "bsln_train = bsln_train.merge(ground[['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg']],\n",
    "                 on=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], how='inner',  suffixes=('_bsln', '_grnd')) #precision use in samples without data / labels\n",
    "bsln_train = pd.get_dummies(bsln_train, columns=['phoneName'])\n",
    "train = bsln_train.drop(['latDeg_grnd', 'lngDeg_grnd', 'collectionName', 'millisSinceGpsEpoch', 'phone'], axis=1)\n",
    "labels = bsln_train[['latDeg_grnd', 'lngDeg_grnd']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the error correction nature of the problem, initially we would like to see how a ML model can reproduce the simple baseline prediction<br>\n",
    "using only its baseline latlon and even try and make it better by using timeseries model such as LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = train[['latDeg_bsln', 'lngDeg_bsln']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split for train/test the data & normilize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for the model to perform better on the data we will normalize our data before feeding it to the model.<br>\n",
    "We chose MinMaxScaler which perform the following `x_i = (x_i - min(X))/(max(X)-min(X))`, the choice has been made <br>\n",
    "due to the need to preserve the order between the lat lon locations.\n",
    "\n",
    "Then we split the normalized dataset to train and validation sets by 80%/20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "n_features = X.shape[1]\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "x_normed = scaler_x.fit_transform(X)\n",
    "y_normed = scaler_y.fit_transform(labels)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_normed, y_normed, random_state=0, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss function\n",
    "Our NN model would be implemented using `tensorflow` library.<br>\n",
    "Because the evaluation metric of the competition is the haversine distance loss, <br>\n",
    "A good NN implementation would reduce this following metric.<br>\n",
    "Therefore we will build a loss function exactly for that.<br>\n",
    "`Keras` library make sure to take into account the gradients calculations using the given loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def haversine_loss(y_true, y_pred):\n",
    "    PI_ON_180 = tf.constant(np.pi / 180, dtype=tf.float32)\n",
    "    RADIUS_M = tf.constant(6_377_000, dtype = tf.float32)\n",
    "    tf.dtypes.cast(y_true, tf.float32)\n",
    "    tf.dtypes.cast(y_pred, tf.float32)\n",
    "\n",
    "    yt_rad = y_true * PI_ON_180\n",
    "    yp_rad = y_pred * PI_ON_180\n",
    "\n",
    "    delta = yt_rad - yp_rad\n",
    "    v = delta / 2\n",
    "    v = tf.sin(v)\n",
    "    v = v**2\n",
    "\n",
    "    a = v[:,1] + tf.cos(yt_rad[:,1]) * tf.cos(yp_rad[:,1]) * v[:,0] \n",
    "    c = tf.sqrt(a)\n",
    "    c = 2* tf.math.asin(c)\n",
    "    c = c*RADIUS_M\n",
    "    \n",
    "    p50 = tfp.stats.percentile(c, 50)\n",
    "    p95 = tfp.stats.percentile(c, 95)\n",
    "    \n",
    "    final = tf.reduce_mean(tf.convert_to_tensor([p50, p95]))\n",
    "    return final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple NN model with only one hidden layer. <br>\n",
    "The use of `tanh` activation function is made due to the continous nature of the results.<br>\n",
    "to make sure we output negative results as well as positive<br>\n",
    "a learning rate of 0.0001 is chosen due to percision and trial & error (with higher learning rates got stuck at local optima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(x_train.shape[1], input_shape=(x_train.shape[1], ), activation='tanh'),\n",
    "    tf.keras.layers.Dense(10, activation='tanh'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "])\n",
    "\n",
    "model.compile(loss=haversine_loss,\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously we learned on the for more than 15000 with 0.00001 learning rate, let's use the previous model and train it for 100 more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reconstructed_model = tf.keras.models.load_model(\"baseline_latlon.hdf5\", compile=False)\n",
    "reconstructed_model.compile(loss=haversine_loss,\n",
    "                optimizer=tf.keras.optimizers.Adam(0.00001))\n",
    "model = reconstructed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "mcp_save = tf.keras.callbacks.ModelCheckpoint('.mdl_wts.hdf5', save_best_only=True, monitor='val_loss', mode='max')\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=100, validation_data=(x_test, y_test), callbacks=[mcp_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(list(range(len(history.history['loss']))), history.history['loss'], label='train_loss', c='r')\n",
    "plt.plot(list(range(len(history.history['loss']))), history.history['val_loss'], alpha=0.5, label='val_loss', c='b', ls='--')\n",
    "plt.ylabel('haversine loss')\n",
    "plt.xlabel('ephoch')\n",
    "plt.title('Learning curve')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = scaler_y.inverse_transform(model.predict(x_test))\n",
    "y_test_reg = scaler_y.inverse_transform(y_test)\n",
    "x_test_reg = scaler_x.inverse_transform(x_test)\n",
    "score_prev = haversine_50thP_95thP_mean(y_test_reg[:,0], y_test_reg[:,1], x_test_reg[:,0], x_test_reg[:,1])\n",
    "score_curr = haversine_50thP_95thP_mean(y_test_reg[:,0], y_test_reg[:,1], pred[:,0], pred[:,1])\n",
    "print(\"{}m error rate from our evaluation metric.\\n an impovement of {}m\".format(score_curr, score_prev-score_curr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_set = bsln_train[bsln_train['phone'] == '2020-05-14-US-MTV-1_Pixel4']\n",
    "X_val = val_set[['latDeg_bsln', 'lngDeg_bsln']]\n",
    "X_val.fillna(0, inplace=True)\n",
    "val_truth = ground[(ground['collectionName'] == '2020-05-14-US-MTV-1')&(ground['phoneName']=='Pixel4')][['latDeg', 'lngDeg']]\n",
    "X_val_norm = scaler_x.fit_transform(X_val)\n",
    "val_truth_norm = scaler_y.fit_transform(val_truth)\n",
    "val_truth_arr = np.array(val_truth[['latDeg', 'lngDeg']])\n",
    "pred = model.predict(X_val_norm)\n",
    "pred = scaler_y.inverse_transform(pred)\n",
    "compareRoutes(val_truth_arr, pred)\n",
    "IFrame(src='./map.html', width=700, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Evaluation:\n",
    "Although the model was fed with baseline input data it actually managed to perform worst than the raw baseline inputs.<br>\n",
    "If we zoom into the learning curve we can see that the curve was negativly inclined, therefore we more epochs I believe the model could converge to at least the baseline performance.<br>\n",
    "In my opinion although the baseline lat lon predictions are nice in order to significally make a change we must incorprate much more data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Datasets model\n",
    "----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2> Learning - regression models </h2>\n",
    "\n",
    "Considering the continous nature of some of the features (speed, X/Y/Z locations, course degrees and etc.) it might be useful to try a some regression models.<br>\n",
    "The input features considered for this model should be numeric, describing different satelite properties from the derived dataset combined with baseline estimations.<br>\n",
    "First, we thought about using the \"pivotted\" set - where derived data that is satellite specific is taken as a seperate feature for each satellite, for example:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "[c for c in list(data.columns) if 'correctedPrM' in c][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the corrected estimated distance from each satellite to a cell phone is count as a seperated feature.<br>\n",
    "For preperation, I'd like to drop categorial data and unneccesary textual and time fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_drop = ['constellationType', 'receivedSvTimeInGpsNanos']\n",
    "df = data.drop([c for c in list(data.columns) if any([cname in c for cname in c_drop])], axis=1)\n",
    "df = df.select_dtypes(include=['float64', 'int64'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before trying to utilize different regression models, we define 2 things:<br>\n",
    "- A scoring method, getting two arrays - prediction values and ground values. It will determine the closeness of the prediction set using the method mentioned in the challenge.<br>\n",
    "- We can guess that some code will repeat itself - splitting data, fitting, predicting, getting the mean score and etc...so to make things concise and to reduce the number of lines of code, we also define a method for this process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def haversine_medians_loss(pred, grnd):\n",
    "    return haversine_50thP_95thP_mean(pred[:,0], pred[:,1], grnd[:,0], grnd[:,1])\n",
    "\n",
    "def utilize_model(model, data, filter_on_train_data=None, predict_columns=['latDeg_grnd', 'lngDeg_grnd'], cv_folds=5):\n",
    "    \"\"\"\n",
    "    Train a model using cross validation test prediction results.\n",
    "    \n",
    "    :param model: A machine learning model object implementing *fit* and *predict* methods    \n",
    "    :param data: A pandas DataFrame object containing columns to train on and columns to predict.\n",
    "    :param predict_columns: an array-like object of columns strings to try and predict\n",
    "    :param cv_folds (optional): how many folds should be used when training and testing (cross-validating).\n",
    "    \"\"\"\n",
    "    Y = data[predict_columns].to_numpy()\n",
    "    X = data.drop(predict_columns, axis=1).to_numpy()\n",
    "    scores = []\n",
    "    kf = KFold(n_splits=cv_folds, shuffle=True)\n",
    "    for train, test in kf.split(X):\n",
    "        model.fit(X[train], (Y[train]))\n",
    "        prediction = model.predict(X[test])\n",
    "        scores.append(haversine_50thP_95thP_mean(prediction[:,0], prediction[:,1], Y[test][:,0], Y[test][:,1]))\n",
    "    scores = np.array(scores)\n",
    "    return scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as a benchmark and for getting a sense of the ability of a regression model to predict - we try to train one based only on baseline lat,lng values.\n",
    "Here the prediction is given by using cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as LR\n",
    "\n",
    "\n",
    "predict_columns = ['latDeg_grnd', 'lngDeg_grnd']\n",
    "basic_baseline_columns = ['latDeg_bsln', 'lngDeg_bsln']\n",
    "\n",
    "lr_df = df[predict_columns + basic_baseline_columns]\n",
    "model = LR()\n",
    "score = utilize_model(model=model, data=lr_df)\n",
    "print(f'Prediction accuracy mean is: {score} meters using the {type(model).__name__} model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the entire data set. <br>\n",
    "Learning based on **all** of it will **fail** as there are NaN values! (in most columns of the data, actually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def columns_with_na_count(df):\n",
    "    return df.isna().any()[lambda i: i].shape[0]\n",
    "\n",
    "print(f'There are {columns_with_na_count(df)} columns containing at least 1 NaN value!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to make up for it. One (very) naive approach is filling the gaps with 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zero_fill_df = df.fillna(0)\n",
    "print(f'There are {columns_with_na_count(zero_fill_df)} columns containing at least 1 NaN value!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for splitting the data, fitting and predicting.<br>\n",
    "Using a linear regression model and the embbeded normalization we get a disappointing result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LR(normalize=True)\n",
    "score = utilize_model(model, data=zero_fill_df)\n",
    "print(f'Prediction accuracy mean is: {score} meters using the {type(model).__name__} model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was expected though. Filling empty values with 0's doesn't make much sense as the values being filled are physical properties of satelittes, some with relation to the cell phone.<br>\n",
    "0s for those values can throw the model way off. We can try a different method for filling missing data that makes more sense.<br>\n",
    "One way to start is to fill empty values by the mean value of their respective columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_fill_df = df.fillna(df.mean())\n",
    "\n",
    "utilize_model(LR(normalize=True), data=mean_fill_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A minor improvment. This could be because mean values entail more meaning then just 0s. Still, this is not an acceptable result.<br>\n",
    "**TODO: try more approaches for this filling issue**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimistic as this approach for missing values may be, the prediction is still very far off. <br>\n",
    "While trying to think of better ways (and implementations) for handeling this problem it occoured to us that using the pivotted data may not be the best idea for regression. <br>\n",
    "Using the derived data in an unpivotted manner may be useful here. The interesting values will still be those that describe continous, physcial properties of the satellites but the categorial, discrete types (like the pivot axis - satelite ID) will be dropped. <br>\n",
    "The reasoning for this decision is that it could be helpful to only concentrate on the phycisal values first (like a location of **a** satelite and its distance from a cell phone) rather than trying to address more complex relationships that this type of model might not be able to describe naturally.<br><br>\n",
    "Simply put - forget about **which** satellite it was, let's try to predict based on **where** it was.<br><br>\n",
    "We'll start by matching the baseline and derived sets with and the ground set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_key = ['collectionName', 'phoneName', 'millisSinceGpsEpoch']\n",
    "\n",
    "bsln_grnd = pd.merge(bsln_trn, ground[sample_key + ['latDeg', 'lngDeg']], how='inner', on=sample_key, suffixes=['', '_grnd'])\n",
    "\n",
    "continous_features = ['correctedPrM', 'xSatPosM', 'ySatPosM', 'zSatPosM', 'xSatVelMps', 'ySatVelMps', 'zSatVelMps', 'satClkBiasM', 'satClkDriftMps']\n",
    "derived_reg = derived[continous_features + sample_key + ['svid']]\n",
    "\n",
    "# group derived by spesific satellite sample\n",
    "drvd_reg_grp = derived_reg.groupby(sample_key + ['svid']).agg('first')  \n",
    "# match with the baselinet and ground sets\n",
    "drvd_bsln_grnd = pd.merge_asof(drvd_reg_grp.sort_values('millisSinceGpsEpoch'), bsln_grnd.sort_values('millisSinceGpsEpoch'), on=['millisSinceGpsEpoch'], tolerance=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drvd_bsln_grnd_clean = drvd_bsln_grnd.dropna()\n",
    "unpivot_data = drvd_bsln_grnd_clean.select_dtypes(include=['int64', 'float64']).drop(['qsSinceGpsEpoch', ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unpivot_data['bsln_grnd_dist'] = calc_haversine(unpivot_data['latDeg'], unpivot_data['lngDeg'], unpivot_data['latDeg_grnd'], unpivot_data['lngDeg_grnd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unpivot_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "utilize_model(LR(normalize=True), filter_on_train_data=(unpivot_data['bsln_grnd_dist'] < 3), data=unpivot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "utilize_model(Lasso(alpha=.2), filter_on_train_data=(unpivot_data['bsln_grnd_dist'] < 3), data=unpivot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet as EN\n",
    "\n",
    "utilize_model(EN(alpha=20, l1_ratio=.5), data=unpivot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try some other regression models, such as the ridge, lasso and elastic net models.<br>\n",
    "Those models are useful in the same sense that the linear regression one is (and indeed the linear model is a special case of those models).<br>\n",
    "They differ by the fact that they use a bias to the slope of the relations they find between the regressor and the predict values. The values that give the lowest variance (distance scoring method in this case) are faovred. Those hyperparameters (alpha value and the l1_ratio for elastic net) are optimized by trial-and-error.<br>\n",
    "**TODO: plot multiple linear models by their different parameters - say ridge and lasso using different alpha settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "alpha_settings = np.concatenate([np.arange(.1,1,.1), np.arange(1,10,1), np.arange(10,100,5)])\n",
    "settings = alpha_settings\n",
    "lasso_scores = []\n",
    "ridge_scores = []\n",
    "for alpha in settings:\n",
    "    lasso_scores.append(utilize_model(Lasso(alpha=alpha), mean_fill_df))\n",
    "    ridge_scores.append(utilize_model(Ridge(alpha=alpha), mean_fill_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_alpha_data = pd.DataFrame({'alpha_value': settings, 'lasso_score': lasso_scores, 'ridge_score': ridge_scores})\n",
    "\n",
    "# todo: plot the performance of those models based on the alpha value!\n",
    "sns.lineplot(data=[model_alpha_data['lasso_score'], model_alpha_data['ridge_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet as EN\n",
    "\n",
    "\n",
    "en_scores = []\n",
    "for alpha in alpha_settings[:10]:\n",
    "    for ratio in np.arange(.2, 1, .2):\n",
    "        en_scores.append((alpha, ratio, utilize_model(EN(alpha=alpha, l1_ratio=ratio), mean_fill_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "en_scores_df = pd.DataFrame(en_scores, columns=['alpha','l1_ratio','score']).round(5)\n",
    "en_scores_df = en_scores_df.pivot('alpha','l1_ratio','score')\n",
    "sns.heatmap(en_scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "Y = mean_fill_df[predict_columns]\n",
    "#X = mean_fill_df.drop(predict_columns, axis=1)\n",
    "X = mean_fill_df[['latDeg_bsln', 'lngDeg_bsln']]\n",
    "\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "x_normed = scaler_x.fit_transform(X)\n",
    "y_normed = scaler_y.fit_transform(Y)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_normed, y_normed, random_state=0, test_size=0.2)\n",
    "\n",
    "y_train_lat = y_train[:,0]\n",
    "y_train_lng = y_train[:,1]\n",
    "\n",
    "model = SGDRegressor(max_iter=5000, loss='huber')\n",
    "model.fit(x_train, y_train_lat)\n",
    "lat_prediction = model.predict(x_test)\n",
    "\n",
    "model = SGDRegressor(max_iter=5000, loss='huber')\n",
    "model.fit(x_train, y_train_lng)\n",
    "lng_prediction = model.predict(x_test)\n",
    "\n",
    "prediction = np.vstack((lat_prediction, lng_prediction)).T\n",
    "y_arr = y_test\n",
    "\n",
    "x_inv = scaler_x.inverse_transform(prediction)\n",
    "y_inv = scaler_y.inverse_transform(y_arr)\n",
    "\n",
    "distance_score = haversine_50thP_95thP_mean(x_inv[:,0], x_inv[:,1], y_inv[:,0], y_inv[:,1])\n",
    "print(f'Prediction accuracy: {distance_score} meters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suggestions for the future\n",
    "\n",
    "- ##### LSTM Neural network<br>\n",
    "To improve the model we would try and use a LSTM network instead of simple one.<br>\n",
    "The LSTM can handle well the nature of time series using deep architecture.<br>\n",
    "I think LSTM can even handle it better than RNN due to the RNN weakness of vanishing gradinent problem over deeper layers.<br>\n",
    "Therefore for each sample we would have a memory of our route, which can help a lot diminishing errors<br>\n",
    "- ##### Use derived dataset<br>\n",
    "Incorprate the derived dataset measurements per satelite with the baseline dataset<br>\n",
    "In order to archive higher level of complexity in our calculation new data must be introduced regarding various parameters such as<br>\n",
    "distance from satelite to device, the location of the satelite and much more<br>\n",
    "- ##### Incorprate historic measurements from similar lat/lon pairs\n",
    "Try and make use of historic measurements from other phones on current phone.\n",
    "Take advantage using other measurements in the same time from other collections\n",
    "- ##### Collect more data using the GNSS Android API\n",
    "Maybe all we need is to introduce some variance to the model<br>\n",
    "By collecting data here in tel aviv we are generelizing our model to work outside san fransisco bay area and less prone to overfitting\n",
    "- ##### Incorprate Accelometer & Gyroscope measurements to the dataset\n",
    "By using features originating from other phone sensors we can roughly predict how the car should move from the first point to the last point<br>\n",
    "Therefore using the kalman filter and introducing the data to the neural network as well we can predict the loss in our baseline prediction and fix it<br>\n",
    "This should be a very promising step, the data is written in raw log measurements therefore it is not easy task to approach neccessaraly\n",
    "- ##### Hyperparameter tuning\n",
    "Using keras tuner to determine the best hyperparameters for our model\n",
    "- ##### Outlier detection\n",
    "Detect outlier measurements and decide on cleaning policy, whether dropping the sample or changing its value to more appropriate one.\n",
    "- ##### Run the notebook on GPU for faster training\n",
    "The training process took 3 days for simple 3 layer model with low learning rate but still it is slow, <br>\n",
    "We would try to run our taining on google colab notebook with GPU in order for faster feedback loop on our model performance.<br>\n",
    "- ##### Use a better filler value for the training pivot table for the regression model\n",
    "Using '0' to fill satelite properties for satelite IDs that samples miss is a bad idea, throwing off the model.\n",
    "- ##### Calculate some more evaluation metrics in order to evaluate better the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bsln_trn.columns, ground.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_key = ['collectionName', 'phoneName', 'millisSinceGpsEpoch']\n",
    "bsln_grnd_trn = pd.merge(left=bsln_trn, right=ground[sample_key + ['latDeg', 'lngDeg']], on=sample_key, suffixes=['', '_grnd'])\n",
    "bsln_grnd_trn['grnd_dist'] = calc_haversine(bsln_grnd_trn['latDeg'], bsln_grnd_trn['lngDeg'], bsln_grnd_trn['latDeg_grnd'], bsln_grnd_trn['lngDeg_grnd'])\n",
    "bsln_grnd_trn[bsln_grnd_trn['grnd_dist'] > 10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "reg_data = data.drop(['receivedSvTimeInGpsNanos', 'qsSinceGpsEpoch'], axis=1)\n",
    "reg_data = reg_data.drop([c for c in reg_data.columns if 'constellationType' in c], axis=1)\n",
    "reg_data = reg_data.drop([c for c in reg_data.columns if 'mean' in c or 'list' in c], axis=1)\n",
    "reg_data = reg_data.drop(['latDeg_prv', 'lngDeg_prv'], axis=1)\n",
    "reg_data = reg_data.select_dtypes(include=['float64'])\n",
    "reg_data[['phone', 'millisSinceGpsEpoch']] = data[['phone', 'millisSinceGpsEpoch']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# continous features\n",
    "features = {'correctedPrM', 'xSatPosM', 'ySatPosM', 'zSatPosM', 'constellationType', 'xSatVelMps', 'ySatVelMps', 'zSatVelMps', 'satClkBiasM', 'satClkDriftMps'  }\n",
    "# get those values from the derived set\n",
    "df = derived[list(features.union({'collectionName', 'phoneName', 'millisSinceGpsEpoch', 'svid'}))].groupby(['collectionName', 'phoneName', 'millisSinceGpsEpoch', 'svid']).mean()\n",
    "df = df.reset_index()\n",
    "# piv = df.pivot_table(values=list(features), index=['collectionName', 'phoneName', 'millisSinceGpsEpoch'], columns=['svid'])\n",
    "# grouped = derived[['phoneName','collectionName', 'millisSinceGpsEpoch', 'receivedSvTimeInGpsNanos', 'epoch_timestamp']].groupby(['phoneName', 'millisSinceGpsEpoch']).max()\n",
    "# piv = piv.merge(grouped, on=['phoneName', 'millisSinceGpsEpoch'])\n",
    "# piv.fillna(-max(derived['correctedPrM']), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped = derived[['phoneName','collectionName', 'millisSinceGpsEpoch', 'receivedSvTimeInGpsNanos', 'epoch_timestamp']].groupby(['phoneName', 'millisSinceGpsEpoch']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.merge(df,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "piv_columns = [c for c in list(reg_data.columns) if len(c) == 2]\n",
    "reg_data[piv_columns].melt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "filled = reg_data.groupby(['millisSinceGpsEpoch']).transform(lambda g: g.fillna(g.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "reg_data.fillna({('correctedPrM', 1) : 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "means = reg_data.groupby('phone').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "merged = pd.merge(reg_data, means, on=['phone'], how='inner', suffixes=('', '_means'))\n",
    "for c in reg_data.columns:\n",
    "    if c is tuple:\n",
    "        merged[c] = merged[c].fillna(merged[tuple(c) + '_means'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "reg_data.fillna(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "filled = reg_data.fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "reg_data.isna().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sel_columns = data.select_dtypes(include=['float64']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "predict_columns = ['latDeg_grnd', 'lngDeg_grnd']\n",
    "baseline_columns = ['latDeg_bsln', 'lngDeg_bsln']\n",
    "X = df[baseline_columns]\n",
    "Y = data[predict_columns]\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=0, test_size=0.2)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "prediction = model.predict(x_test)\n",
    "y_arr = y_test.to_numpy()\n",
    "distance_score = haversine_50thP_95thP_mean(prediction[:,0], prediction[:,1], y_arr[:,0], y_arr[:,1])\n",
    "\n",
    "print(f'Prediction accuracy: {distance_score} meters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def linear_regression(X, Y, cv_iter=5, scoring=haversine_medians_loss):\n",
    "#     model = LinearRegression(normalize=True)\n",
    "#     scorer = None\n",
    "#     if scoring is not None:\n",
    "#         scorer = make_scorer(scoring)\n",
    "#     scores = cross_val_score(model, X.to_numpy(), Y.to_numpy(), cv=cv_iter, scoring=scorer)\n",
    "#     print(f'scores: {scores}')    \n",
    "#     print(f'mean: {scores.mean()} meters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
